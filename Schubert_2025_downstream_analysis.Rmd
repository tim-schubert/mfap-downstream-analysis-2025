---
title: "Downstream analysis"
author: "Tim Schubert"
date: "2026-02-21"
output:
  html_document: default
  pdf_document: default
---

# Setup

```{r setup, include=FALSE}
# Project-rooted paths
library(here)
library(dplyr)
library(tidyverse)

output_dir <- here("output")
plots_dir  <- file.path(output_dir, "plots")
tables_dir <- file.path(output_dir, "tables")
base_out   <- file.path(output_dir, "regression studies")
data_dir   <- here("data")

invisible(dir.create(output_dir, recursive = TRUE, showWarnings = FALSE))
invisible(dir.create(plots_dir,  recursive = TRUE, showWarnings = FALSE))
invisible(dir.create(tables_dir, recursive = TRUE, showWarnings = FALSE))
invisible(dir.create(base_out,   recursive = TRUE, showWarnings = FALSE))
invisible(dir.create(data_dir,   recursive = TRUE, showWarnings = FALSE))

```

# Downstream analysis

## Maintenance and Diagnostics

### Load saved MAP output and variant list

```{r load results_df, warning=FALSE, message=FALSE}
results_df <- readRDS(file.path(output_dir, "results_df.rds"))
variant_list <- read_csv("Variant_list.csv")
```

### Severity Score

This is to analyze the impact of available information on severity outcomes.

#### Severity score diagnostics

```{r severity-score-diagnostics, echo=TRUE, message=FALSE, warning=FALSE}
library(tidyverse)
library(ggridges)
library(viridisLite)
library(patchwork)
library(grid)

df_all <- severity_diagnostics_df %>%
  transmute(
    severity = as.numeric(S_without_tau),
    Smax     = as.numeric(S_max)
  ) %>%
  tidyr::drop_na()

cuts       <- seq(0, max(df_all$Smax), by = 5)
cut_labels <- paste0("\u2265", cuts)
pal        <- viridis(length(cuts), alpha = 0.65)
names(pal) <- cut_labels

# ============================================================================
# PANEL 1: Ridgeline plot
# ============================================================================
ridge_df <- map_dfr(cuts, \(c) 
    df_all %>% 
      filter(Smax >= c) %>% 
      mutate(cut_lab = paste0("\u2265", c))
  ) %>% 
  mutate(cut_lab = factor(cut_lab, levels = cut_labels))

p_ridge <- ggplot(ridge_df, aes(x = severity, y = cut_lab, fill = cut_lab)) +
  geom_density_ridges(
    scale = 3, rel_min_height = .01,
    colour = "grey15", size = .3, alpha = .65
  ) +
  scale_fill_manual(values = pal, name = expression(S[max]*" threshold")) +
  scale_x_continuous(breaks = c(0, 0.5, 1)) +
  labs(
    x = expression("Severity score  "*S[without~tau]),
    y = expression("Lower bound on "*S[max])
  ) +
  theme_classic() +
  theme(
    axis.text.y      = element_text(size = 8),
    text             = element_text(face = "bold", family = "Helvetica")
  )


# Save ridgeline plot
out_dir <- file.path(output_dir, "severity score diagnostics")
if (!dir.exists(out_dir)) dir.create(out_dir, recursive = TRUE)

ggsave(
  filename = file.path(out_dir, "severity_score_ridgeline.pdf"),
  plot     = p_ridge,
  width    = 4,
  height   = 3,
  device   = cairo_pdf,
  dpi      = 300
)

# ============================================================================
# PANEL 2: Correlation plot
# ============================================================================


corr_df <- map_dfr(cuts, function(c) {
    d <- df_all %>% filter(Smax >= c)
    if (nrow(d) < 4) return(tibble(cut = c, rho = NA, p = NA, n = nrow(d)))
    ct <- cor.test(d$Smax, d$severity, method = "spearman")
    tibble(
      cut = c,
      rho = unname(ct$estimate),
      p   = ct$p.value,
      n   = nrow(d)
    )
  }) %>% 
  mutate(
    z       = atanh(rho),
    se      = 1 / sqrt(pmax(n - 3, 1)),
    lo      = tanh(z - 1.96*se),
    hi      = tanh(z + 1.96*se),
    cut_lab = factor(paste0("\u2265", cut), levels = cut_labels)
  )

p_corr <- ggplot(corr_df, aes(x = cut, y = rho, colour = cut_lab)) +
  geom_hline(yintercept = 0, linetype = "dotted", colour = "grey60") +
  geom_errorbar(aes(ymin = lo, ymax = hi), width = .6, linewidth = .6) +
  geom_point(
    data = subset(corr_df, p >= .05),
    size = 3.5, shape = 21, stroke = 1.2, fill = "white"
  ) +
  geom_point(
    data = subset(corr_df, p < .05),
    aes(fill = cut_lab),
    size = 3.5, shape = 21, stroke = 1.2
  ) + 
  scale_colour_manual(values = pal, name = expression(S[max]*" threshold")) +
  scale_fill_manual(values = pal, guide = "none") +
  scale_x_continuous(breaks = cuts) +
  labs(
    x = expression("Lower bound on "*S[max]),
    y = expression("Spearman "*rho)
  ) +
  theme_classic() +
  theme(
    text            = element_text(face = "bold", family = "Helvetica"),
    axis.text       = element_text(colour = "black")
  )

# Save correlation plot
ggsave(
  filename = file.path(out_dir, "severity_score_correlation.pdf"),
  plot     = p_corr,
  width    = 4,
  height   = 3,
  device   = cairo_pdf,
  dpi      = 300
)

# ============================================================================
# PANEL 3: QQ-plot panel
# ============================================================================
thresholds <- cuts[1:6]
th_labels  <- paste0("\u2265", thresholds)
pal6       <- pal[th_labels]

qq_df <- map_dfr(thresholds, function(cut) {
    df_all %>% 
      filter(Smax >= cut) %>% 
      transmute(severity, cut_lab = paste0("\u2265", cut))
  }) %>% 
  mutate(cut_lab = factor(cut_lab, levels = th_labels))

annot_df <- qq_df %>% 
  count(cut_lab) %>% 
  mutate(label = paste0("n = ", n))

n_max        <- max(annot_df$n)
theo_limits  <- qnorm(c(0.5/n_max, 1 - 0.5/n_max))
sample_limits <- range(qq_df$severity)

p_qq6 <- ggplot(qq_df, aes(sample = severity, colour = cut_lab)) +
  stat_qq(size = 1.5, alpha = 0.6, shape=16) +
  stat_qq_line(size = 0.8) +
  facet_wrap(~cut_lab, ncol = 3) +
  geom_text(
    data    = annot_df,
    aes(x = Inf, y = -Inf, label = label),
    hjust   = 1.1, vjust = -0.5,
    size    = 3.5,
    inherit.aes = FALSE
  ) +
  scale_colour_manual(
    values = pal6,
    name   = expression(S[max]*" threshold")
  ) +
  labs(
    x = "Theoretical Quantiles",
    y = "Sample Quantiles"
  ) +
  coord_cartesian(
    xlim = theo_limits,
    ylim = sample_limits
  ) +
  theme_classic(base_family = "Helvetica", base_size = 13) +
  theme(
    text            = element_text(face = "bold", colour = "black"),
    axis.text       = element_text(colour = "black"),
    axis.title      = element_text(colour = "black"),
    strip.text      = element_text(size = 10, face = "bold"),
    panel.border    = element_rect(fill = NA, colour = "black"),
    panel.spacing   = unit(0.5, "lines"),
    legend.position = "none",
    aspect.ratio    = 1
  )

# Save QQ-plot
ggsave(
  filename = file.path(out_dir, "severity_score_qq_panel.pdf"),
  plot     = p_qq6,
  width    = 5,
  height   = 5,
  device   = cairo_pdf,
  dpi      = 300
)

# ============================================================================
# COMBINED FIGURE 
# ============================================================================
figure <- (p_ridge | p_qq6) / p_corr +
  plot_layout(guides = "collect") &
  theme(
    legend.position   = "right",
    legend.box.margin = margin(0, 10, 0, 0),
    text              = element_text(face = "bold", family = "Helvetica")
  )

ggsave(
  filename = file.path(out_dir, "severity_score_diagnostics_full.pdf"),
  plot     = figure,
  width    = 10,
  height   = 12,
  device   = cairo_pdf,
  dpi      = 300
)
```

#### Retention

```{r retention-curve, echo=TRUE, message=FALSE, warning=FALSE}

suppressPackageStartupMessages({ library(scales) })

smax_max   <- ceiling(max(df_all$Smax, na.rm = TRUE))
fine_cuts  <- seq(0, smax_max, by = 1)

km_fine <- tibble(cut = fine_cuts) %>%
    rowwise() %>%
    mutate(n = sum(df_all$Smax >= cut, na.rm = TRUE)) %>%
    ungroup() %>%
    mutate(
        frac = if (max(n) > 0) n / max(n) else NA_real_
    )

# markers 
km_marks <- tibble(cut = sort(cuts)) %>%
    rowwise() %>%
    mutate(n = sum(df_all$Smax >= cut, na.rm = TRUE)) %>%
    ungroup() %>%
    mutate(
        frac    = n / max(n),
        cut_lab = factor(paste0("\u2265", cut), levels = cut_labels)
    )

n0 <- km_fine$n[1]

p_km_separate <- ggplot() +
    # 1-point resolution step curve
    geom_step(data = km_fine, aes(x = cut, y = frac), linewidth = 0.4) +
    geom_point(
        data   = km_marks,
        aes(x = cut, y = frac, colour = cut_lab),
        size   = 3, shape = 16
    ) +
    scale_colour_manual(values = pal, name = expression(S[max]*" threshold")) +
    scale_x_continuous(breaks = cuts) +
    scale_y_continuous(
        labels  = percent_format(accuracy = 1),
        limits  = c(0, 1),
        sec.axis = sec_axis(~ . * n0, name = "Individuals retained (n)")
    ) +
    labs(
        x = expression("Lower bound on "*S[max]),
        y = "Fraction of cohort retained",
        title = "Retention vs. Smax threshold"
    ) +
    theme_classic() +
    theme(
        text            = element_text(face = "bold", family = "Helvetica"),
        axis.text       = element_text(colour = "black"),
        axis.title      = element_text(colour = "black"),
        legend.position = "right"
    )

# Save 
out_dir <- file.path(output_dir, "severity score diagnostics")
if (!dir.exists(out_dir)) dir.create(out_dir, recursive = TRUE)

ggsave(
    filename = file.path(out_dir, "severity_retention_curve_narrow.png"),
    plot     = p_km_separate,
    width    = 4,     
    height   = 3.2,  
    dpi      = 300
)

ggsave(
    filename = file.path(out_dir, "severity_retention_curve_narrow.pdf"),
    plot     = p_km_separate,
    width    = 4,
    height   = 3.2,
    device = cairo_pdf,
    dpi = 300
)

```

Given the outcome, we consider the severity values for patients with max. achievable points \< 10 as NA.

```{r replace-severity-below-threshold, message=FALSE, warning=FALSE}
library(dplyr)

# Replace severity with NA for patients with max_achievable_points < 10
results_df <- results_df %>%
  mutate(severity = if_else(max_achievable_points < 10, NA_real_, severity))

# Preview
head(results_df)
```

#### Severity \~ IQ

```{r severity-iq-model}

library(tidyverse)
library(broom)
library(ggplot2)
library(viridisLite)

## Linear model: Severity ~ IQ

lm_iq <- lm(severity ~ IQ, data = results_df)

print(summary(lm_iq))

cat("\n--- Coefficients ---\n")
tidy_iq <- tidy(lm_iq, conf.int = TRUE)
print(tidy_iq)

cat("\n--- Model Statistics ---\n")
glance_iq <- glance(lm_iq)
print(glance_iq)

cat("\n--- Sample Size ---\n")
cat("N observations:", nobs(lm_iq), "\n")
cat("N missing IQ:", sum(is.na(results_df$IQ)), "\n")
cat("N missing severity:", sum(is.na(results_df$severity)), "\n")


model_output <- glance_iq %>%
  mutate(
    n_missing_IQ = sum(is.na(results_df$IQ)),
    n_missing_severity = sum(is.na(results_df$severity))
  )

write_csv(model_output, file.path(out_dir, "severity_iq_model_output.csv"))


## Plot
# Get viridis color for threshold ≥10
cuts <- seq(0, 30, by = 5)
pal <- viridis(length(cuts), alpha = 0.65)
color_threshold_10 <- pal[3]

# Model statistics for plot annotation
r2_iq <- round(summary(lm_iq)$r.squared, 3)
p_iq <- summary(lm_iq)$coefficients[2, 4]
p_text_iq <- ifelse(p_iq < 0.001, "p < 0.001", 
                    paste("p =", round(p_iq, 4)))
n_iq <- nobs(lm_iq)

p_severity_iq <- ggplot(results_df, aes(x = IQ, y = severity)) +
  geom_point(
    shape = 16,
    size = 2.5,
    colour = color_threshold_10,
    alpha = 0.65
  ) +
  geom_smooth(
    method = "lm",
    se = TRUE,
    colour = "black",
    linewidth = 0.8,
    fill = "grey70",
    alpha = 0.2
  ) +
  annotate(
    "text",
    x = Inf, y = Inf,
    label = paste0("R² = ", r2_iq, "\n", p_text_iq, "\nn = ", n_iq),
    hjust = 1.1, vjust = 1.1,
    size = 3.5,
    fontface = "bold",
    family = "Helvetica"
  ) +
  labs(
    x = "IQ",
    y = "Severity score  S"
  ) +
  theme_classic(base_family = "Helvetica", base_size = 13) +
  theme(
    text = element_text(face = "bold", colour = "black"),
    axis.text = element_text(colour = "black"),
    axis.title = element_text(colour = "black") 
  ) +
  coord_flip() +
  scale_y_continuous(limits = c(0, 1))

print(p_severity_iq)

ggsave(
  filename = file.path(out_dir, "severity_iq_plot.pdf"),
  plot = p_severity_iq,
  width = 3,
  height = 3,
  dpi = 300
)
```

#### Leave-on-out sensitivity analysis

```{r leave-one-out-analysis}

# SYS Severity Score + Leave-One-Out (LOO) sensitivity

suppressPackageStartupMessages({
  library(dplyr)
  library(purrr)
  library(tidyr)
  library(ggplot2)
})

# -----------------------------
# Constants
# -----------------------------
TAU <- 10

WHO_90P <- list(
  sit        = 7.5,
  crawl      = 10.5,
  walk_alone = 14.4
)

SPEECH_REF <- list(
  first_word       = 14,
  two_word_sentence = 24
)

SPEECH_DELAY_CUTOFF <- 12

# -----------------------------
# Small utilities
# -----------------------------
`%||%` <- function(x, y) {
  if (is.null(x) || length(x) == 0 || (length(x) == 1 && is.na(x))) y else x
}

sym_id <- function(name) {
  x <- tolower(name)
  x <- gsub("[^a-z0-9]+", "_", x)
  x <- gsub("^_+|_+$", "", x)
  x
}

as_num <- function(x) suppressWarnings(as.numeric(x))

# -----------------------------
# CSV column name mapping
# -----------------------------
COLMAP <- c(
  id             = "patient_ID",
  age_sit        = "age_months_sitting",
  age_crawl      = "age_months_crawling",
  age_walk       = "age_months_walking",
  age_first_word = "age_months_1st_words",
  age_two_word   = "age_months_1st_2_words",
  id_status      = "ID_any_kind",
  iq             = "ID_IQ",
  ow_status      = "overweight_issues_any",
  sa_status      = "sleep_apnea_any",
  sa_sev         = "sleep_apnea_severe",
  rd_status      = "respiratory_distress_any",
  rd_sev         = "respiratory_distress_severe",

  bin_muscular_hypotonia =
    "muscular_hypotonia_any_kind",
  bin_feeding_difficulties_excl_hyperphagia =
    "feeding_difficulties_any_kind_except_hyperphagia",
  bin_hyperphagia = "hyperphagia",
  bin_underweight = "underweight_issues",
  bin_chronic_constipation = "chronic_constipation",
  bin_gastroesophageal_reflux_gerd = "GERD",
  bin_contractures_and_or_arthrogryposis =
    "contractures_or_arthrogryposis",
  bin_scoliosis_or_kyphosis =
    "scoliosis_or_kyphosis",
  bin_seizures_or_epilepsy =
    "seizures_or_epilepsy",
  bin_ocular_issues =
    "ocular_anomalies",
  bin_genitourinary_issues =
    "genitourinary_anomalies",
  bin_gh_deficiency =
    "GH_deficiency",
  bin_endocrine_issues =
    "any_other_hypothalamic_dysfunction",
  bin_autistic_behavior =
    "autism",
  bin_anxiety =
    "anxiety",
  bin_other_behavioral_issues_except_asd_and_anxiety =
    "temper_tantrums_impulsivity"
)

standardize_columns <- function(df, colmap) {
  stopifnot(is.data.frame(df), is.character(colmap), !is.null(names(colmap)))

  for (internal_name in names(colmap)) {
    csv_name <- unname(colmap[[internal_name]])
    if (csv_name %in% names(df)) {
      df[[internal_name]] <- df[[csv_name]]
    }
  }
  df
}

# -----------------------------
# Symptom definitions
# -----------------------------
symptom_rules <- tibble::tribble(
  ~Symptom, ~Weight, ~Group, ~B_i,
  "Motor delay", 2.0, "A", 1.5,
  "Speech delay", 2.0, "A", 1.5,
  "Intellectual Disability", 2.0, "B", 1.5,
  "Muscular hypotonia", 2.0, "Binary", 1.0,
  "Feeding difficulties (excl. hyperphagia)", 2.0, "Binary", 1.0,
  "Hyperphagia", 1.0, "Binary", 1.0,
  "Overweight", 1.0, "B", 1.5,
  "Underweight", 0.5, "Binary", 1.0,
  "Chronic constipation", 2.0, "Binary", 1.0,
  "Gastroesophageal reflux (GERD)", 2.0, "Binary", 1.0,
  "Sleep apnea", 2.0, "B", 1.5,
  "Respiratory distress", 1.0, "B", 1.5,
  "Contractures (and/or arthrogryposis)", 1.0, "Binary", 1.0,
  "Scoliosis or kyphosis", 1.0, "Binary", 1.0,
  "Seizures or epilepsy", 0.5, "Binary", 1.0,
  "Ocular issues", 1.0, "Binary", 1.0,
  "Genitourinary issues", 0.5, "Binary", 1.0,
  "GH deficiency", 1.0, "Binary", 1.0,
  "Endocrine issues", 0.5, "Binary", 1.0,
  "Autistic behavior", 1.0, "Binary", 1.0,
  "Anxiety", 1.0, "Binary", 1.0,
  "Other behavioral issues (except ASD and anxiety)", 1.0, "Binary", 1.0
)

# -----------------------------
# helpers
# -----------------------------
parse_achievement <- function(value) {
  num <- as_num(value)
  if (is.na(num)) return("unknown")
  if (num == -1) return("no")
  "yes"
}

compute_motor_bi <- function(ach_sit, sit_age, ach_crawl, crawl_age, ach_walk, walk_age) {
  status <- c(parse_achievement(ach_sit), parse_achievement(ach_crawl), parse_achievement(ach_walk))
  if (any(status == "no")) return(1.5)

  sit_age   <- as_num(sit_age)
  crawl_age <- as_num(crawl_age)
  walk_age  <- as_num(walk_age)

  delayed <- c(
    sit_age   > WHO_90P$sit,
    crawl_age > WHO_90P$crawl,
    walk_age  > WHO_90P$walk_alone
  )

  delayed[status != "yes"] <- NA
  if (all(is.na(delayed))) return(NA_real_)

  n <- sum(delayed, na.rm = TRUE)
  if (n >= 2) return(1.25)
  if (n == 1) return(1.0)
  0
}

compute_speech_bi <- function(ach_fw, fw_age, ach_2w, tw_age) {
  status <- c(parse_achievement(ach_fw), parse_achievement(ach_2w))
  if (any(status == "no")) return(1.5)

  fw_age <- as_num(fw_age)
  tw_age <- as_num(tw_age)

  delayed <- c(
    fw_age - SPEECH_REF$first_word > SPEECH_DELAY_CUTOFF,
    tw_age - SPEECH_REF$two_word_sentence > SPEECH_DELAY_CUTOFF
  )

  moderate <- c(
    fw_age - SPEECH_REF$first_word > 6,
    tw_age - SPEECH_REF$two_word_sentence > 6
  )

  delayed[status != "yes"] <- NA
  moderate[status != "yes"] <- NA
  if (all(is.na(delayed))) return(NA_real_)

  if (sum(delayed, na.rm = TRUE) >= 2) return(1.25)
  if (sum(moderate, na.rm = TRUE) >= 1) return(1.0)
  0
}

compute_id_bi <- function(status, iq) {
  s <- as_num(status)
  if (is.na(s)) return(NA_real_)
  if (s == 0) return(0)

  iq <- as_num(iq)
  if (is.na(iq)) return(1.0)
  if (iq < 30) return(1.5)
  if (iq < 50) return(1.25)
  if (iq < 70) return(1.0)
  1.0
}

compute_overweight_bi <- function(status) {
  s <- as_num(status)
  if (is.na(s)) return(NA_real_)
  if (s %in% c(0, 0.5, 1, 1.5)) return(s)
  NA_real_
}

compute_sa_bi <- function(status, sev) {
  s <- as_num(status)
  if (is.na(s)) return(NA_real_)
  if (s == 0) return(0)

  severe <- as_num(sev)
  if (!is.na(severe) && severe == 1) return(1.5)
  1.0
}

compute_rd_bi <- function(status, sev) {
  s <- as_num(status)
  if (is.na(s)) return(NA_real_)
  if (s == 0) return(0)

  severe <- as_num(sev)
  if (!is.na(severe) && severe == 1) return(1.5)
  1.0
}

compute_any1_bi <- function(...) {
  vals <- as_num(c(...))
  if (all(is.na(vals))) return(NA_real_)
  if (any(vals == 1, na.rm = TRUE)) return(1)
  0
}

get_binary_symptom <- function(row, symptom) {
  col <- paste0("bin_", sym_id(symptom))
  if (!col %in% names(row)) return(NA_real_)

  v <- row[[col]][[1]]
  if (is.na(v)) return(NA_real_)

  n <- as_num(v)
  if (!is.na(n)) {
    if (n == 0) return(0)
    if (n == 1) return(1)
  }

  v <- tolower(trimws(as.character(v)))
  if (v %in% c("0", "absent", "no")) return(0)
  if (v %in% c("1", "present", "yes")) return(1)

  NA_real_
}

# -----------------------------
# Main Scoring Function
# -----------------------------
score_sys <- function(df, colmap = COLMAP, tau = TAU) {
  df <- standardize_columns(df, colmap)

  items <- purrr::map_dfr(seq_len(nrow(df)), function(i) {
    row <- df[i, , drop = FALSE]
    pull1 <- function(nm) if (nm %in% names(row)) row[[nm]][[1]] else NA

    purrr::pmap_dfr(symptom_rules, function(Symptom, Weight, Group, B_i) {
      b_i <- NA_real_

      if (Symptom == "Motor delay") {
        b_i <- compute_motor_bi(
          pull1("age_sit"), pull1("age_sit"),
          pull1("age_crawl"), pull1("age_crawl"),
          pull1("age_walk"), pull1("age_walk")
        )
      } else if (Symptom == "Speech delay") {
        b_i <- compute_speech_bi(
          pull1("age_first_word"), pull1("age_first_word"),
          pull1("age_two_word"), pull1("age_two_word")
        )
      } else if (Symptom == "Intellectual Disability") {
        b_i <- compute_id_bi(pull1("id_status"), pull1("iq"))
      } else if (Symptom == "Overweight") {
        b_i <- compute_overweight_bi(pull1("ow_status"))
      } else if (Symptom == "Sleep apnea") {
        b_i <- compute_sa_bi(pull1("sa_status"), pull1("sa_sev"))
      } else if (Symptom == "Respiratory distress") {
        b_i <- compute_rd_bi(pull1("rd_status"), pull1("rd_sev"))
      } else if (Symptom == "Endocrine issues") {
        b_i <- compute_any1_bi(
          pull1("temperature_instability"),
          pull1("endocrine_and_metabolic_dysfunction_any_kind"),
          pull1("hyperprolactinemia"),
          pull1("hormone_deficiency_not_specified"),
          pull1("hypoglycemia_or_hyperinsulinism"),
          pull1("diabetes_mellitus"),
          pull1("diabetes_insipidus"),
          pull1("hypothyroidism"),
          pull1("adrenal_insufficiency")
        )
      } else if (Symptom == "Other behavioral issues (except ASD and anxiety)") {
        b_i <- compute_any1_bi(
          pull1("temper_tantrums_impulsivity"),
          pull1("hyperactivity"),
          pull1("self_mutilating_behavior"),
          pull1("lying_deceitfulness"),
          pull1("depressive_mood"),
          pull1("stubbornness")
        )
      } else if (Symptom == "Genitourinary issues") {
        b_i <- compute_any1_bi(
          pull1("genitourinary_anomalies"),
          pull1("hypogonadism")
        )
      } else if (Symptom == "Muscular hypotonia") {
        b_i <- compute_any1_bi(
          pull1("muscular_hypotonia_any_kind"),
          pull1("reduced_fetal_movement")
        )
      } else if (Group == "Binary") {
        b_i <- get_binary_symptom(row, Symptom)
      }

      known <- !is.na(b_i)

      tibble(
        id         = pull1("id") %||% as.character(i),
        Symptom    = Symptom,
        Weight     = Weight,
        B_i        = B_i,
        b_i        = b_i,
        w_times_bi = if (known) Weight * b_i else NA_real_,
        known      = known
      )
    })
  })

  summary <- items %>%
    group_by(id) %>%
    summarise(
      S_raw = sum(w_times_bi[known], na.rm = TRUE),
      S_max = sum((Weight * B_i)[known], na.rm = TRUE),
      S = ifelse(!is.na(S_max) & S_max >= tau & S_max > 0, S_raw / S_max, NA_real_),
      tau_ok = !is.na(S),
      .groups = "drop"
    )

  list(summary = summary, items = items)
}

# -----------------------------
# Leave-one-out sensitivity analysis function
# -----------------------------
loo_sensitivity <- function(scored, tau = TAU) {
  items <- scored$items
  summary <- scored$summary

  purrr::map_dfr(unique(items$id), function(pid) {
    df_pid <- items %>% filter(id == pid)
    S_orig <- summary %>% filter(id == pid) %>% pull(S)

    df_assessed <- df_pid %>% filter(known)
    m <- nrow(df_assessed)

    # ---- FIX: handle individuals with no assessed symptoms ----
    if (m == 0) {
      return(tibble(id = pid, S_original = S_orig, m = 0L))
    }

    loo_list <- vector("list", length = m)
    names(loo_list) <- paste0("S_loo_", vapply(df_assessed$Symptom, sym_id, character(1)))

    for (k in seq_len(m)) {
      tmp <- df_pid
      sym_name <- df_assessed$Symptom[k]
      idx <- which(tmp$Symptom == sym_name & tmp$known)[1]

      tmp$b_i[idx] <- NA_real_
      tmp$known[idx] <- FALSE
      tmp$w_times_bi[idx] <- NA_real_

      S_raw <- sum(tmp$w_times_bi[tmp$known], na.rm = TRUE)
      S_max <- sum((tmp$Weight * tmp$B_i)[tmp$known], na.rm = TRUE)
      loo_list[[k]] <- if (!is.na(S_max) && S_max >= tau && S_max > 0) S_raw / S_max else NA_real_
    }

    tibble(id = pid, S_original = S_orig, m = m, !!!loo_list)
  })
}

write_csv_safe <- function(df, file) {
  stopifnot(is.data.frame(df), is.character(file), length(file) == 1)
  write.csv(df, file = file, row.names = FALSE, na = "")
  invisible(normalizePath(file, mustWork = FALSE))
}

plot_loo_scatter <- function(loo_results, out_file = "output_plots/SYS_LOO_scatter.pdf") {
  suppressPackageStartupMessages({
    library(dplyr)
    library(tidyr)
    library(ggplot2)
  })

  original_scores <- loo_results %>%
    select(id, S_original) %>%
    filter(!is.na(S_original)) %>%
    mutate(id = as.character(id))

  loo_long <- loo_results %>%
    select(id, starts_with("S_loo_")) %>%
    pivot_longer(cols = -id, names_to = "symptom", values_to = "S_loo") %>%
    mutate(id = as.character(id), S_loo = as.numeric(S_loo)) %>%
    filter(!is.na(S_loo))

  scatter_df <- loo_long %>%
    left_join(original_scores, by = "id") %>%
    filter(!is.na(S_original)) %>%
    arrange(S_original)

  lm_fit <- lm(S_loo ~ S_original, data = scatter_df)
  smry   <- summary(lm_fit)

  coefs <- smry$coefficients
  conf  <- confint(lm_fit)

  intercept <- unname(coefs["(Intercept)", "Estimate"])
  slope     <- unname(coefs["S_original", "Estimate"])

  intercept_p <- unname(coefs["(Intercept)", "Pr(>|t|)"])
  slope_p     <- unname(coefs["S_original", "Pr(>|t|)"])

  intercept_ci <- conf["(Intercept)", ]
  slope_ci     <- conf["S_original", ]

  r2    <- smry$r.squared
  adjr2 <- smry$adj.r.squared
  n     <- nobs(lm_fit)

  rmse <- sqrt(mean(residuals(lm_fit)^2, na.rm = TRUE))

  fmt_p <- function(p) {
    if (is.na(p)) return("NA")
    if (p < 2.2e-16) return("< 2.2e-16")
    if (p < 0.001) return(format(p, scientific = TRUE, digits = 2))
    sprintf("%.3f", p)
  }

  ann <- paste0(
    "N = ", n, "\n",
    "R\u00B2 = ", sprintf("%.3f", r2), " (adj. ", sprintf("%.3f", adjr2), ")\n",
    "RMSE = ", sprintf("%.3f", rmse), "\n",
    "Slope = ", sprintf("%.3f", slope),
    " [", sprintf("%.3f", slope_ci[1]), ", ", sprintf("%.3f", slope_ci[2]), "]",
    ", p = ", fmt_p(slope_p), "\n",
    "Intercept = ", sprintf("%.3f", intercept),
    " [", sprintf("%.3f", intercept_ci[1]), ", ", sprintf("%.3f", intercept_ci[2]), "]",
    ", p = ", fmt_p(intercept_p)
  )

  p <- ggplot(scatter_df, aes(x = S_original, y = S_loo)) +
    geom_abline(intercept = 0, slope = 1, linewidth = 0.4) +
    geom_smooth(method = "lm", se = FALSE, linewidth = 0.4) +
    geom_point(size = 1, alpha = 0.5, shape = 16, color = "#316990") +
    annotate("text",
      x = 0.05, y = 0.95, hjust = 0, vjust = 1,
      label = ann, size = 3, lineheight = 1.05
    ) +
    scale_x_continuous(limits = c(0, 1), expand = expansion(mult = c(0.02, 0.05))) +
    scale_y_continuous(limits = c(0, 1), expand = expansion(mult = c(0.02, 0.05))) +
    theme_classic(base_size = 12) +
    labs(x = "Original severity score", y = "LOO severity score")

  dir.create(dirname(out_file), recursive = TRUE, showWarnings = FALSE)
  ggsave(out_file, plot = p, width = 3, height = 3.0, dpi = 300)
  p
}

# -----------------------------
# run
# -----------------------------
df <- read.csv("data/SYS_data_July_2024_TS_updated_HP_Feb_2026.csv", stringsAsFactors = FALSE)
scored <- score_sys(df)
loo <- loo_sensitivity(scored)
write_csv_safe(scored$summary, "SYS_scores_summary.csv")
write_csv_safe(scored$items,   "SYS_scores_items.csv")
write_csv_safe(loo,           "SYS_LOO_sensitivity_results.csv")
plot_loo_scatter(loo,         "output_plots/SYS_LOO_scatter.pdf")



# -----------------------------
# Calculate the mean absolute difference for each individual 
# + the mean across all individuals
# -----------------------------
mean_loo_abs_difference <- function(loo_results) {
  loo_cols <- grep("^S_loo_", names(loo_results), value = TRUE)
  if (length(loo_cols) == 0) stop("No S_loo_* columns found in loo_results")

  diff_df <- loo_results %>%
    rowwise() %>%
    mutate(
      abs_diffs = list(abs(as.numeric(c_across(all_of(loo_cols))) - S_original)),
      mean_abs_diff = if (all(is.na(abs_diffs))) NA_real_ else mean(abs_diffs, na.rm = TRUE)
    ) %>%
    ungroup() %>%
    select(id, mean_abs_diff)

  overall_mean_abs_diff <- mean(diff_df$mean_abs_diff, na.rm = TRUE)

  list(
    per_patient = diff_df,
    overall_mean_abs_diff = overall_mean_abs_diff
  )
}

loo_abs_diff <- mean_loo_abs_difference(loo)

loo_abs_diff$per_patient
loo_abs_diff$overall_mean_abs_diff
```

### Renaming variables for clarity

```{r rename-symptoms, message=FALSE, warning=FALSE}
library(dplyr)

# rename map
original_rename_map <- c(
  "DD_(any)" = "DD",
  "DD_(motor_delay)" = "motor delay",
  "DD_(speech_delay)" = "delayed speech",
  "ID_(any)" = "ID",
  "muscular_hypotonia" = "hypotonia",
  "feeding_difficulties_except_hyperphagia" = "feeding difficulties",
  "overweight_issues" = "overweight",
  "short_or_characteristic_hands_or_feet" = "short extremities",
  "dysmorphic_features" = "dysmorphism",
  "contractures_or_arthrogryposis" = "contractures",
  "scoliosis_or_kyphosis" = "scoliosis",
  "seizures_or_epilepsy" = "epilepsy",
  "ocular_anomalies" = "ocular issues",
  "genitourinary_anomalies" = "genitourinary issues",
  "endocrine_or_metabolic_dysfunction_(any)" = "endocrine issues",
  "hypoglycemia_or_hyperinsulinism" = "hypoglycemia",
  "underweight issues" = "underweight"
)

flipped_rename_map <- setNames(names(original_rename_map), original_rename_map)

# Filter the flipped map to include only columns that exist in results_df.
existing_rename <- flipped_rename_map[flipped_rename_map %in% colnames(results_df)]

# Create a new data frame with clean variable names.
results_df_w_clean_names <- results_df %>% rename(!!!existing_rename)

# Read the variable categorization CSV file.
var_cat <- read_csv(file.path(data_dir, "variable_categorization_with_additional_info.csv"))

if("Clean_Name" %in% colnames(var_cat)){
  message("Column 'Clean_Name' exists; updating its values.")
} else {
  message("Column 'Clean_Name' does not exist; adding new column.")
}

# Add the Clean_Name column:
var_cat <- var_cat %>% 
  mutate(Clean_Name = if_else(Variable %in% names(original_rename_map),
                              original_rename_map[Variable],
                              gsub("_", " ", Variable)))

# write csv
write_csv(var_cat, file.path(data_dir, "variable_categorization_with_additional_info.csv"))
cat("Updated variable categorization file saved with 'Clean_Name' column.\n")
# Print new column names for verification.
print(colnames(results_df_w_clean_names))
```

### Clean-up "lost domains" col

```{r clean-lost-domains, message=FALSE, warning=FALSE}
library(dplyr)
library(stringr)
library(purrr)

results_df <- results_df %>%
  # 1) keep a copy of the original
  mutate(orig_Lost_Functional_Domains = Lost_Functional_Domains) %>%
  
  # 2) rebuild Lost_Functional_Domains with u7bs_mhd → u7bs + mhd, drop after_mhd
  mutate(
    Lost_Functional_Domains = case_when(
      is.na(orig_Lost_Functional_Domains) ~ NA_character_,
      TRUE ~ orig_Lost_Functional_Domains %>%
        str_split(",\\s*") %>% 
        map_chr(function(parts) {
          # remove after_mhd
          parts <- setdiff(parts, "after_mhd")
          
          # if u7bs_mhd was in the original, remove it and add u7bs & mhd
          if ("u7bs_mhd" %in% parts) {
            parts <- setdiff(parts, "u7bs_mhd")
            parts <- c(parts, "u7bs", "mhd")
          }
          
          # drop duplicates, handle empty → NA, else re-join
          parts <- unique(parts)
          if (length(parts) == 0) NA_character_
          else paste(parts, collapse = ", ")
        })
    )
  )

# Quick check
results_df %>%
  select(orig_Lost_Functional_Domains, Lost_Functional_Domains) %>%
  head()

```

### Fix previous frameshift analysis issue

Ensure there are no "0" values in frameshift length (could previously be the case for very specific constellations and is correct in principle but we do not want to include these patients in analyses of frameshift length but instead only perform the frameshift length analysis for patients with a true frameshifting indel variant). This is fixed in the updated version of the MfAP pipeline.

```{r replace-frameshift-zeros, echo=TRUE, message=FALSE}
# Show how many zeros are present before replacement
zeros_before <- sum(results_df$`Frameshift_Length_[aa]` == 0, na.rm = TRUE)
cat("Zeros before replacement:", zeros_before, "\n")

# Replace zeros with NA
results_df$`Frameshift_Length_[aa]`[results_df$`Frameshift_Length_[aa]` == 0] <- NA

# Show counts after replacement
zeros_after <- sum(results_df$`Frameshift_Length_[aa]` == 0, na.rm = TRUE)
nas_after  <- sum(is.na(results_df$`Frameshift_Length_[aa]`))
cat("Zeros after replacement:", zeros_after, "\n")
cat("NAs after replacement:", nas_after, "\n")
```

## Further Downstream Analysis

### Descriptive statistics on genotype variables

```{r genotype_descriptives_and_save, message=FALSE, warning=FALSE}

library(tidyverse)
library(janitor)
library(knitr)
library(writexl)

# 1) Identify Genotype variables and split by type
geno_vars      <- var_cat %>% filter(Genotype_or_Phenotype == "Genotype")
cat_geno_vars  <- geno_vars %>% filter(str_detect(Type, "Cate|Bina")) %>% pull(Variable)
cont_geno_vars <- geno_vars %>% filter(str_detect(Type, "Cont"))         %>% pull(Variable)

# 2A) Continuous genotype variable summaries
cont_summary <- map_dfr(cont_geno_vars, function(var) {
  vec <- results_df[[var]]
  tibble(
    Variable = var,
    n        = sum(!is.na(vec)),
    mean     = mean(vec, na.rm = TRUE),
    sd       = sd(vec,   na.rm = TRUE),
    median   = median(vec, na.rm = TRUE),
    IQR      = IQR(vec,    na.rm = TRUE),
    min      = min(vec,    na.rm = TRUE),
    max      = max(vec,    na.rm = TRUE)
  )
}) %>%
  left_join(var_cat %>% select(Variable, Clean_Name), by = "Variable") %>%
  select(Clean_Name, everything(), -Variable)

# 2B) Categorical (including binary) genotype variable summaries
cat_summary <- map_dfr(cat_geno_vars, function(var) {
  levs <- as.character(results_df[[var]])
  tb   <- table(levs, useNA = "no")
  tibble(
    Variable = var,
    Level    = names(tb),
    Count    = as.integer(tb)
  )
}) %>%
  group_by(Variable) %>%
  mutate(Percent = round(Count / sum(Count) * 100, 1)) %>%
  ungroup() %>%
  left_join(var_cat %>% select(Variable, Clean_Name), by = "Variable") %>%
  select(Clean_Name, Level, Count, Percent)

# 3) Print tables in the report
kable(cont_summary, caption = "Descriptive statistics for continuous genotype variables", 
      col.names = c("Variable", "n", "Mean", "SD", "Median", "IQR", "Min", "Max"))
kable(cat_summary,  caption = "Counts and percentages for categorical genotype variables", 
      col.names = c("Variable", "Level", "Count", "Percent"))

# 4) Save both summaries to an Excel file
save_path <- file.path(tables_dir, "descriptive statistics on genotype variables.xlsx")
dir.create(dirname(save_path), recursive = TRUE, showWarnings = FALSE)
write_xlsx(
  list(
    Continuous  = cont_summary,
    Categorical = cat_summary
  ),
  path = save_path
)
```


### Severity by genotype variables

#### Categorical genotype variables

For categorical genotype variables, analysis (ANOVA) was performed in PRISM 10.

#### Continuous genotype variables

Standard Diagnostics:

```{r linear-regression-diagnostics, warning=FALSE}

# 1. Define diagnostics output directories
diag_out      <- file.path(base_out, "diagnostics")
combined_diag <- file.path(diag_out, "combined")
female_diag   <- file.path(diag_out, "female")
male_diag     <- file.path(diag_out, "male")

dir.create(combined_diag, recursive = TRUE, showWarnings = FALSE)
dir.create(female_diag,   recursive = TRUE, showWarnings = FALSE)
dir.create(male_diag,     recursive = TRUE, showWarnings = FALSE)

geno_cont_vars<-c("Locus", "Protein_Length_[aa]", "Frameshift_Length_[aa]")

# 2. Loop over each continuous genotype variable
purrr::walk(geno_cont_vars, function(var) {
  # prepare data
  df_var <- results_df %>%
    dplyr::select(sex, severity, !!rlang::sym(var)) %>%
    dplyr::rename(predictor = !!rlang::sym(var)) %>%
    tidyr::drop_na()

  # skip variables with insufficient data
  if (nrow(df_var) < 2) return()

  # fit models only where at least 2 cases exist
  fits <- list(
    Combined = df_var,
    Female   = df_var %>% dplyr::filter(sex == "f"),
    Male     = df_var %>% dplyr::filter(sex == "m")
  ) %>%
    purrr::keep(~ nrow(.x) >= 2) %>%
    purrr::imap(~ stats::lm(severity ~ predictor, data = .x))

  # save per group
  purrr::iwalk(fits, function(fit, grp) {
    out_dir  <- switch(grp,
                       Combined = combined_diag,
                       Female   = female_diag,
                       Male     = male_diag)
    png_file <- file.path(out_dir, paste0("diag_", tolower(grp), "_", var, ".png"))

    png(filename = png_file,
        width    = 10, height = 10, units = "in",
        res      = 300, type = "cairo")

    par(mfrow = c(2, 2),
        oma   = c(0, 0, 4, 0), 
        mar   = c(5, 4, 2, 1)) 

    plot(fit,
         which       = c(1, 2, 3, 5),
         caption     = "",
         sub.caption = "",
         ask         = FALSE)

    mtext(
      text   = paste("Diagnostics for", grp, "model on", var),
      side   = 3,
      outer  = TRUE,
      line   = 2,
      font   = 2,
      cex    = 1.4
    )

    dev.off()
  })
})
```

→ Protein_Length_from_most_likely_non_canonical_TIS not suitable

**Linear Regression**

We define 3 continuous genotype variables of interest. Others are either perfectly correlated with another variable or have too many missing values. We then fit sex-by-genotype interaction models (**Severity** \~ predictor x sex) for these continuous genotype variables, and extract sex-specific slopes, the marginal (population-average) slope via `emmeans::emtrends()`, and the interaction effect from the linear model. We calculate q values within each effect family using the Benjamini-Hochberg method

```{r interaction-with-counts-and-diagnostics, message=TRUE, warning=FALSE}

library(dplyr)
library(broom)
library(emmeans)
library(tidyr)
library(purrr)
library(openxlsx)
library(ggplot2)
library(scales)
library(extrafont)

# If fonts aren't loaded yet, run this once (commented out after first use):
# font_import(prompt = FALSE)
# loadfonts()

# Define genotype variables and output directories
geno_vars <- c("Locus", "Protein_Length_[aa]", "Frameshift_Length_[aa]")
base_out     <- file.path(output_dir, "regression studies")
int_out      <- file.path(base_out, "interaction regression (selected geno × sex)")
fig_combined <- file.path(int_out, "figures/combined")
fig_by_sex   <- file.path(int_out, "figures/by_sex")
sex_colors   <- c(f = "#D81B60", m = "#1E88E5")

dirs <- c(int_out, fig_combined, fig_by_sex)
purrr::walk(dirs, ~ if (!dir.exists(.x)) { dir.create(.x, recursive=TRUE); message("Created ", .x) } else message(.x, " exists"))

# Prepare data
df_reg <- results_df %>%
  select(patient_ID, sex, severity, all_of(geno_vars)) %>%
  filter(!is.na(severity)) %>%
  mutate(sex = factor(sex, levels = c("f","m")))

# Fit models, extract slopes, compute counts
interaction_res <- purrr::map_dfr(geno_vars, function(var) {
  df_var <- df_reg %>% select(severity, sex, predictor = !!sym(var)) %>% drop_na()
  n_total  <- nrow(df_var)
  n_female <- sum(df_var$sex == "f")
  n_male   <- sum(df_var$sex == "m")
  if (n_distinct(df_var$sex) < 2 || length(unique(df_var$predictor)) < 2) {
    return(tibble(
      Variable       = var,
      n_total        = n_total,
      n_female       = n_female,
      n_male         = n_male,
      Term           = c("FemSlope","MaleSlope","MarginalSlope","Interaction"),
      Estimate       = NA_real_,
      SE             = NA_real_,
      df             = NA_real_,
      lower.CL       = NA_real_,
      upper.CL       = NA_real_,
      p.value        = NA_real_,
      q.value        = NA_real_,
      R2             = NA_real_
    ))
  }
  # Fit model
  fit <- lm(severity ~ predictor * sex, data = df_var)
  r2  <- summary(fit)$r.squared

  # Sex-specific slopes
  et  <- emtrends(fit, ~sex, var = "predictor")
  thr <- summary(et, infer = TRUE) %>% rename(trend = predictor.trend)

  # Marginal slope
  emm <- emtrends(fit, ~1, var = "predictor")
  mar <- summary(emm, infer = TRUE) %>% rename(trend = predictor.trend)

  # Interaction
  it <- tidy(fit, conf.int = TRUE) %>%
    filter(term == "predictor:sexm") %>%
    transmute(
      Term      = "Interaction",
      Estimate  = estimate,
      SE        = std.error,
      df        = NA_real_,
      lower.CL  = conf.low,
      upper.CL  = conf.high,
      p.value   = p.value
    )

  # Combine rows
  bind_rows(
    tibble(
      Variable = var, n_total = n_total, n_female = n_female, n_male = n_male,
      Term     = "FemSlope",
      Estimate = thr$trend[thr$sex == "f"],
      SE       = thr$SE[thr$sex == "f"],
      df       = thr$df[thr$sex == "f"],
      lower.CL = thr$lower.CL[thr$sex == "f"],
      upper.CL = thr$upper.CL[thr$sex == "f"],
      p.value  = thr$p.value[thr$sex == "f"]
    ),
    tibble(
      Variable = var, n_total = n_total, n_female = n_female, n_male = n_male,
      Term     = "MaleSlope",
      Estimate = thr$trend[thr$sex == "m"],
      SE       = thr$SE[thr$sex == "m"],
      df       = thr$df[thr$sex == "m"],
      lower.CL = thr$lower.CL[thr$sex == "m"],
      upper.CL = thr$upper.CL[thr$sex == "m"],
      p.value  = thr$p.value[thr$sex == "m"]
    ),
    tibble(
      Variable = var, n_total = n_total, n_female = n_female, n_male = n_male,
      Term     = "MarginalSlope",
      Estimate = mar$trend,
      SE       = mar$SE,
      df       = mar$df,
      lower.CL = mar$lower.CL,
      upper.CL = mar$upper.CL,
      p.value  = mar$p.value
    ),
    it %>% mutate(Variable = var, n_total = n_total, n_female = n_female, n_male = n_male)
  ) %>% mutate(R2 = r2)
})

# 6. BH-adjust p-values within each term
interaction_res <- interaction_res %>%
  group_by(Term) %>%
  mutate(q.value = p.adjust(p.value, method = "BH")) %>%
  ungroup()

# 7. Pivot to wide and reorder columns
summary_wide <- interaction_res %>%
  pivot_wider(
    id_cols    = c(Variable, n_total, n_female, n_male, R2),
    names_from = Term,
    values_from= c(Estimate, SE, lower.CL, upper.CL, p.value, q.value),
    names_glue = "{Term}_{.value}"
  ) %>%
  select(
    Variable, n_total, n_female, n_male, R2,
    # FemSlope 
    starts_with("FemSlope_Estimate"), starts_with("FemSlope_SE"),
    starts_with("FemSlope_lower.CL"), starts_with("FemSlope_upper.CL"),
    starts_with("FemSlope_p.value"), starts_with("FemSlope_q.value"),
    # MaleSlope 
    starts_with("MaleSlope_Estimate"), starts_with("MaleSlope_SE"),
    starts_with("MaleSlope_lower.CL"), starts_with("MaleSlope_upper.CL"),
    starts_with("MaleSlope_p.value"), starts_with("MaleSlope_q.value"),
    # MarginalSlope 
    starts_with("MarginalSlope_Estimate"), starts_with("MarginalSlope_SE"),
    starts_with("MarginalSlope_lower.CL"), starts_with("MarginalSlope_upper.CL"),
    starts_with("MarginalSlope_p.value"), starts_with("MarginalSlope_q.value"),
    # Interaction 
    starts_with("Interaction_Estimate"), starts_with("Interaction_SE"),
    starts_with("Interaction_lower.CL"), starts_with("Interaction_upper.CL"),
    starts_with("Interaction_p.value"), starts_with("Interaction_q.value")
  )
print(head(summary_wide))

# 8. Write Excel
out_file <- file.path(int_out, "selected_geno_sex_interaction_summary.xlsx")
write.xlsx(summary_wide, file = out_file, overwrite = TRUE)
message("Wrote Excel to: ", out_file)
message("Excel exists? ", file.exists(out_file))

# 9. Plotting
for (var in geno_vars) {
  df_var <- df_reg %>% select(severity, sex, predictor = !!sym(var)) %>% drop_na()
  if (nrow(df_var) < 2 || length(unique(df_var$predictor)) < 2) next
  p_int <- summary_wide %>% filter(Variable == var) %>% pull(Interaction_p.value)
  new_x <- seq(min(df_var$predictor), max(df_var$predictor), length.out = 200)
  fit_c <- lm(severity ~ predictor, data = df_var)
  pr_c  <- predict(fit_c, newdata = data.frame(predictor = new_x), se.fit = TRUE)
  z95   <- qnorm(0.975)
  plot_c <- tibble(
    predictor = new_x,
    fit       = pr_c$fit,
    lower     = pr_c$fit - z95 * pr_c$se.fit,
    upper     = pr_c$fit + z95 * pr_c$se.fit
  )
  pt_map <- aes(x = predictor, y = severity, shape = sex, fill = sex, color = sex)

  if (!is.na(p_int) && p_int < 0.05) {
    for (s in c("f","m")) {
      df_s <- filter(df_var, sex == s)
      if (nrow(df_s) < 2) next
      fit_s <- lm(severity ~ predictor, data = df_s)
      pr_s  <- predict(fit_s, newdata = data.frame(predictor = new_x), se.fit = TRUE)
      plot_s <- tibble(
        predictor = new_x,
        fit       = pr_s$fit,
        lower     = pr_s$fit - z95 * pr_s$se.fit,
        upper     = pr_s$fit + z95 * pr_s$se.fit
      )
      p <- ggplot(df_s, pt_map) +
        geom_point(size = 2, stroke = 0.5, alpha = 0.28) +
        scale_shape_manual(values = c(f = 16, m = 15)) +
        scale_fill_manual(values = sex_colors) +
        scale_color_manual(values = sex_colors) +
        geom_ribbon(data = plot_s,
                    aes(x = predictor, ymin = lower, ymax = upper),
                    inherit.aes = FALSE, fill = "black", alpha = 0.1) +
        geom_line(data = plot_s,
                  aes(x = predictor, y = fit),
                  inherit.aes = FALSE, color = "black", size = 1) +
        scale_x_continuous(expand = expansion(mult = c(0, 0.05)),
                           limits = c(0, NA),
                           breaks = pretty_breaks(n = 5),
                           minor_breaks = pretty_breaks(n = 10)) +
        scale_y_continuous(limits = c(0, 1),
                           breaks = seq(0, 1, 0.2),
                           minor_breaks = seq(0, 1, 0.1)) +
        labs(
          title = paste(var, "–", ifelse(s == "f", "Female", "Male"),
                        "interaction p=", sprintf("%.3f", p_int)),
          x     = var,
          y     = "Severity"
        ) +
        theme_minimal(base_size = 18, base_family = "sans") +
        theme(
          text       = element_text(face = "bold"),
          panel.grid = element_blank(),
          axis.line  = element_line(color = "black"),
          axis.ticks = element_line(color = "black"),
          axis.title = element_text(color = "black"),
          axis.text  = element_text(color = "black")
        )
      ggsave(
        filename = paste0(s, "_", var, ".png"),
        plot     = p,
        path     = fig_by_sex,
        width    = 5.5,
        height   = 4,
        dpi      = 900
      )
    }
  }
  p_all <- ggplot(df_var, pt_map) +
    geom_point(size = 2, stroke = 0.5, alpha = 0.28) +
    scale_shape_manual(values = c(f = 16, m = 15)) +
    scale_fill_manual(values = sex_colors) +
    scale_color_manual(values = sex_colors) +
    geom_ribbon(data = plot_c,
                aes(x = predictor, ymin = lower, ymax = upper),
                inherit.aes = FALSE, fill = "black", alpha = 0.1) +
    geom_line(data = plot_c,
              aes(x = predictor, y = fit),
              inherit.aes = FALSE, color = "black", size = 1) +
    scale_x_continuous(expand = expansion(mult = c(0, 0.05)),
                       limits = c(0, NA),
                       breaks = pretty_breaks(n = 5),
                       minor_breaks = pretty_breaks(n = 10)) +
    scale_y_continuous(limits = c(0, 1),
                       breaks = seq(0, 1, 0.2),
                       minor_breaks = seq(0, 1, 0.1)) +
    labs(title = paste("Severity vs", var), x = var, y = "Severity") +
    theme_minimal(base_size = 18, base_family = "sans") +
    theme(
      text       = element_text(face = "bold"),
      panel.grid = element_blank(),
      axis.line  = element_line(color = "black"),
      axis.ticks = element_line(color = "black"),
      axis.title = element_text(color = "black"),
      axis.text  = element_text(color = "black")
    )
  ggsave(
    filename = paste0("combined_", var, ".png"),
    plot     = p_all,
    path     = fig_combined,
    width    = 5.5,
    height   = 4,
    dpi      = 900
  )
  
  ggsave(
    filename = paste0("combined_", var, ".pdf"),
    plot = p_all, path = fig_combined,
    width = 5.5, height = 4, device = "pdf"
  )
}
```

### Phenotype by genotype variables

#### Categorical genotype variables

**Generation of Supplemental Table:**

We compute for each binary symptom its prevalence (%) and 95% Wilson confidence interval overall and within each genotype level (retaining only levels with ≥5 individuals). We then construct a 2×k contingency table per symptom and genotype variable. When k=2, we apply Boschloo's test. When k\>2, we use Pearson's χ² (without Yates correction) falling back to Fisher-Freeman-Halton when any expected frequency is \<5. We adjust global p-values using the Benjamini-Hochberg method. Only factors with global q\<0.1 undergo post-hoc pairwise tests (Boschloo). Again, p-values are corrected using the Benjamini-Hochberg method.

```{r build-prevalence-and-posthoc-tables-by-group, message=FALSE, warning=FALSE}
library(dplyr)
library(readr)
library(tidyr)
library(purrr)
library(binom)
library(exact2x2)

# Wilson CI for a binary vector
compute_prevalence_stats <- function(x) {
  n_obs <- sum(!is.na(x))
  n_aff <- sum(x == 1, na.rm=TRUE)
  if(n_obs == 0) return(list(ratio="0/0", prev=NA, ci="NA", n=0))
  ratio <- paste0(n_aff, "/", n_obs)
  prev  <- round(100 * n_aff / n_obs, 1)
  bt    <- binom.confint(n_aff, n_obs, methods="wilson")
  ci    <- paste0(round(100 * bt$lower,1), "-", round(100 * bt$upper,1))
  list(ratio=ratio, prev=prev, ci=ci, n=n_obs)
}

build_prevalence_and_posthoc_tables_by_group <- function(group_var, output_folder) {
  # 1) load symptom list & names
  var_cat  <- read_csv("variable_categorization_with_additional_info.csv", show_col_types=FALSE)
  symptoms <- var_cat %>% filter(Measure=="Prevalence") %>% pull(Variable)
  name_map <- setNames(var_cat$Clean_Name, var_cat$Variable)
  
  # 2) valid genotype levels with ≥5 subjects
  counts    <- table(results_df[[group_var]])
  valid_lvls <- names(counts[counts >= 5])
  if(length(valid_lvls) < 2) stop("Not enough levels for ", group_var)
  
  overall_list <- list()
  posthoc_list <- list()
  
  for(symp in symptoms) {
    # 3) build contingency table
    x_all <- results_df[[symp]]
    ct <- sapply(valid_lvls, function(lvl) {
      xi <- x_all[results_df[[group_var]]==lvl]
      c(sum(xi==0,na.rm=TRUE), sum(xi==1,na.rm=TRUE))
    })
    ct <- matrix(ct, nrow=2, byrow=FALSE,
                 dimnames=list(c("Absent","Present"), valid_lvls))
    
    # 4) global test
    p_glob <- NA; test_glob <- "Insufficient data"; min_exp <- NA
    if(sum(ct)>0) {
      if(ncol(ct)==2) {
        a1<-ct["Present",1]; n1<-sum(ct[,1])
        a2<-ct["Present",2]; n2<-sum(ct[,2])
        res <- exact2x2::boschloo(a1,n1,a2,n2)
        test_glob <- "Boschloo"; p_glob <- res$p.value
      } else {
        ch <- suppressWarnings(chisq.test(ct, correct=FALSE))
        min_exp <- min(ch$expected)
        if(min_exp >= 5) {
          test_glob <- "Chi-square"; p_glob <- ch$p.value
        } else if(all(rowSums(ct)>0) && all(colSums(ct)>0)) {
          fr <- fisher.test(ct)
          test_glob <- "Fisher–Freeman–Halton"; p_glob <- fr$p.value
        }
      }
    }
    q_glob <- if(!is.na(p_glob)) p.adjust(p_glob, method="BH") else NA_real_
    
    # 5) per-level prevalence + CI
    lvl_stats <- map(valid_lvls, function(lvl) {
      st <- compute_prevalence_stats(x_all[results_df[[group_var]]==lvl])
      c(Ratio=st$ratio, Prev=st$prev, CI=st$ci, N=st$n)
    }) %>% unlist()
    col_nms <- unlist(map(valid_lvls, ~ paste0(.x, c("_Ratio","_Prev","_CI","_N"))))
    names(lvl_stats) <- col_nms
    
    # 6) post-hoc if global q<0.1
    posthoc_summary <- NA_character_
    if(!is.na(q_glob) && q_glob < 0.1) {
      pairs <- combn(valid_lvls,2, simplify=FALSE)
      ph <- map_dfr(pairs, function(pr) {
        l1<-pr[1]; l2<-pr[2]
        a1<-ct["Present",l1]; n1<-sum(ct[,l1])
        a2<-ct["Present",l2]; n2<-sum(ct[,l2])
        r2 <- exact2x2::boschloo(a1,n1,a2,n2)
        tibble(
          Symptom      = name_map[[symp]] %||% symp,
          Pair         = paste(l1,"vs",l2),
          Pair_Test    = "Boschloo",
          Pair_p.value = r2$p.value
        )
      }) %>% mutate(pairwise_q = p.adjust(Pair_p.value, "BH"))
      posthoc_summary <- paste(
        sprintf("%s: p=%.3g,q=%.3g", ph$Pair, ph$Pair_p.value, ph$pairwise_q),
        collapse=" | "
      )
      posthoc_list[[symp]] <- ph
    }
    
    overall_list[[symp]] <- tibble(
      Symptom         = name_map[[symp]] %||% symp,
      !!!as.list(lvl_stats),
      TestUsed        = test_glob,
      p.value         = p_glob,
      min.expected    = min_exp,
      q.value         = q_glob,
      PostHoc_Summary = posthoc_summary
    )
  }
  
  overall_df <- bind_rows(overall_list)
  posthoc_df  <- bind_rows(posthoc_list)
  
  dir.create(output_folder, recursive=TRUE, showWarnings=FALSE)
  write_csv(overall_df, file.path(output_folder, paste0("prevalence_by_",group_var,".csv")))
  write_csv(posthoc_df,  file.path(output_folder, paste0("posthoc_by_",   group_var,".csv")))
  message("Done: ", group_var)
}

# run over all categorical genotype vars
group_vars <- c(
  "Mutation_Type",
  "Domain_Location_Of_Variant",
  "Lost_Functional_Domains",
  "Lost_Functional_Domains_in_protein_from_non_canonical_in_frame_TIS",
  "1996dupC",
  "lost_signals"
)
output_folder <- "output/tables/prevalence_by_genotype"

purrr::walk(group_vars,
            ~ build_prevalence_and_posthoc_tables_by_group(.x, output_folder)
)
```

**Generation of genotype-variable-specific Radar Charts:**

```{r radar-charts-for-categorical-genotype-variables, message=FALSE, warning=FALSE}
library(dplyr)
library(tidyr)
library(ggradar)
library(scales)
library(ggplot2)
library(readr)
library(openxlsx)

include_vars <- c("hypotonia", "GERD", "respiratory distress", 
                  "contractures", "scoliosis", "short extremities")

group_vars <- c("Mutation_Type", 
                "Domain_Location_Of_Variant", 
                "Lost_Functional_Domains", 
                "Lost_Functional_Domains_in_protein_from_non_canonical_in_frame_TIS", 
                "1996dupC", 
                "lost_signals")

# Paths
input_folder <- file.path(tables_dir, "symptom prevalence for categorical genotype variables")
plots_folder <- plots_dir
if (!dir.exists(plots_folder)) dir.create(plots_folder, recursive = TRUE)

# Colors
group_colors <- c("#E69F00", "#56B4E9", "#009E73", "#CC79A7", "#BCB334")

for (group in group_vars) {
  
  # Read prevalence table
  overall_file <- file.path(input_folder, paste0("prevalence_by_", group, ".csv"))
  overall_df   <- read_csv(overall_file, show_col_types = TRUE)
  
  # Filter symptoms
  radar_df <- overall_df %>% 
    filter(Symptom %in% include_vars)
  
  # Find prevalence columns
  prevalence_cols <- grep("_Prevalence$", colnames(radar_df), value = TRUE)
  
  # Long format
  radar_long <- radar_df %>%
    dplyr::select(Symptom, all_of(prevalence_cols)) %>%
    pivot_longer(
      cols      = -Symptom,
      names_to  = "Group",
      values_to = "Prevalence"
    ) %>%
    mutate(
      Group = gsub("_Prevalence", "", Group),
      Group = gsub("_", " ", Group)
    )
  
  # Wide format + scale & replace NAs only in numeric columns
  radar_wide <- radar_long %>%
    pivot_wider(names_from = Symptom, values_from = Prevalence) %>%
    mutate(Group = as.factor(Group)) %>%
    dplyr::select(Group, all_of(include_vars)) %>%
    mutate(across(-Group, ~ replace_na(.x / 100, 0)))
  
  # Axis labels
  symptom_labels <- include_vars
  symptom_labels[symptom_labels == "respiratory distress"] <- "respiratory\ndistress"
  symptom_labels[symptom_labels == "short extremities"]   <- "short\nextremities"
  colnames(radar_wide)[-1] <- symptom_labels
  
  # Reorder levels
  if (group == "Domain_Location_Of_Variant") {
    radar_wide$Group <- factor(radar_wide$Group,
      levels = c("proline rich", "u7bs", "mhd")
    )
  }
  if (group == "Lost_Functional_Domains") {
    radar_wide$Group <- factor(radar_wide$Group,
      levels = c(
        "proline rich", 
        "proline rich, u7bs, mhd",
        "u7bs",
        "u7bs, mhd",
        "mhd"
      )
    )
  }
  if (group == "Mutation_Type") {
    radar_wide$Group <- factor(radar_wide$Group,
      levels = c(
        "Frameshifting indel", 
        "Nonsense",
        "Missense"
      )
    )
  }
  
  # Colors
  used_colors <- group_colors[ seq_along(unique(radar_wide$Group)) ]
  
  # Build radar chart
  p <- ggradar(
    radar_wide,
    grid.min                      = 0,
    grid.mid                      = 0.5,
    grid.max                      = 1,
    grid.label.size               = 3,
    values.radar                  = c("", "", ""),
    axis.label.size               = 2,
    axis.label.offset             = 1.15,
    plot.legend                   = TRUE,
    plot.extent.x.sf              = 1.3,
    plot.extent.y.sf              = 1.3,
    gridline.min.linetype         = "dashed",
    gridline.mid.linetype         = "dashed",
    gridline.max.linetype         = "dashed",
    gridline.min.colour           = "grey70",
    gridline.mid.colour           = "grey70",
    gridline.max.colour           = "grey70",
    background.circle.colour      = "grey90",
    background.circle.transparency = 0.2,
    group.colours                 = used_colors,
    fill                          = TRUE,
    fill.alpha                    = 0.1,
    group.point.size              = 0
  ) +
    scale_fill_manual(values = used_colors) +
    scale_color_manual(values = used_colors) +
    guides(
      fill  = guide_legend(title = "", ncol = 1),
      color = guide_legend(title = "", ncol = 1)
    ) +
    theme(
      legend.text   = element_text(size = 5, face = "bold", family = "Arial"),
      axis.text     = element_text(size = 5,  face = "bold", family = "Arial"),
      legend.position      = c(-0.5, 0),
      legend.justification = c(0, 0),
      plot.margin          = margin(t = 10, r = 30, b = 10, l = 30, unit = "pt")
    )
  
  # Save
  output_file <- file.path(plots_folder, paste0("radar_plot_", group, ".png"))
  ggsave(output_file, p, width = 10, height = 3, dpi = 300)
  cat("Radar plot for", group, "saved to:", output_file, "\n")
  print(p)
}
```

#### Continuous genotype variables

**Logistic regression**

Given that only Protein length was significantly associated with severity, we use only protein length as a predictor and focus on those symptoms that are part of the SYS severity score. We include symptoms with ≥10 individual cases and both sexes. We fit logistic models using glm(..., family=binomial) to regress each symptom on protein length, sex, and their interaction. We compute performance (AUC, Brier). We call emmeans::emtrends() to estimate sex-specific and marginal slopes and CIs. We use the Benjamini-Hochberg method within each Term to calculate q values. We exponentiate the marginal log-odds slope to yield ORs per aa and per 100aa.

```{r logistic-severity-emmeans-eval, message=FALSE, warning=FALSE}

library(dplyr)
library(tidyr)
library(purrr)
library(broom)
library(emmeans)
library(pROC)
library(readr)

# norm function
norm_ci <- function(tb) {
  tb <- as_tibble(tb)
  if (!"lower.CL" %in% names(tb) && "asymp.LCL" %in% names(tb)) tb$lower.CL <- tb$asymp.LCL
  if (!"upper.CL" %in% names(tb) && "asymp.UCL" %in% names(tb)) tb$upper.CL <- tb$asymp.UCL
  tb
}

# 1) Setup
var_cat <- read_csv(file.path(data_dir, "variable_categorization_with_additional_info.csv"))
severity_symptoms <- var_cat %>%
  filter(Measure == "Prevalence", part_severity_score == "yes") %>%
  pull(Variable)
predictor   <- "Protein_Length_[aa]"
out_dir_int <- file.path(base_out, "logistic regression severity symptoms by Protein Length interaction model")
dir.create(out_dir_int, recursive = TRUE, showWarnings = FALSE)

# 2) Fit & gather
logistic_res <- severity_symptoms %>%
  set_names() %>%
  map_dfr(function(symptom) {
    df <- results_df %>%
      select(y = all_of(symptom), x = all_of(predictor), sex) %>%
      drop_na() %>%
      mutate(sex = factor(sex, levels = c("f","m")))  

    N0 <- sum(df$y == 0); N1 <- sum(df$y == 1); Nsex <- n_distinct(df$sex)
    if (N0 < 10 || N1 < 10 || Nsex < 2) {
      return(tibble(
        Symptom = symptom, N0 = N0, N1 = N1, Nsex = Nsex,
        Term = c("FemSlope","MaleSlope","MarginalSlope","Interaction"),
        Estimate = NA_real_, SE = NA_real_, df = NA_real_,
        lower.CL = NA_real_, upper.CL = NA_real_,
        p.value = NA_real_, q.value = NA_real_,
        AUC = NA_real_, Brier = NA_real_
      ))
    }

    fit     <- glm(y ~ x * sex, data = df, family = binomial)
    phat    <- predict(fit, type = "response")
    auc_val <- as.numeric(roc(df$y, phat)$auc)
    brier   <- mean((phat - df$y)^2)

    # sex-specific slopes 
    et  <- emtrends(fit, ~ sex, var = "x")
    thr <- summary(et, infer = c(TRUE, TRUE)) %>%
      norm_ci() %>%
      rename(trend = x.trend)

    fem <- thr %>% filter(sex == "f")
    mal <- thr %>% filter(sex == "m")

    # marginal slope
    emm <- emtrends(fit, ~ 1, var = "x")
    mar <- summary(emm, infer = c(TRUE, TRUE)) %>%
      norm_ci() %>%
      rename(trend = x.trend)

    # interaction term
    it <- tidy(fit, conf.int = TRUE) %>%
      filter(grepl("x:sexm|sexm:x", term)) %>%
      transmute(
        Term     = "Interaction",
        Estimate = estimate,
        SE       = std.error,
        df       = NA_real_,
        lower.CL = conf.low,
        upper.CL = conf.high,
        p.value  = p.value
      )

    bind_rows(
      tibble(
        Symptom = symptom, N0 = N0, N1 = N1, Nsex = Nsex, Term = "FemSlope",
        Estimate = fem$trend, SE = fem$SE, df = fem$df,
        lower.CL = fem$lower.CL, upper.CL = fem$upper.CL,
        p.value = fem$p.value
      ),
      tibble(
        Symptom = symptom, N0 = N0, N1 = N1, Nsex = Nsex, Term = "MaleSlope",
        Estimate = mal$trend, SE = mal$SE, df = mal$df,
        lower.CL = mal$lower.CL, upper.CL = mal$upper.CL,
        p.value = mal$p.value
      ),
      tibble(
        Symptom = symptom, N0 = N0, N1 = N1, Nsex = Nsex, Term = "MarginalSlope",
        Estimate = mar$trend, SE = mar$SE, df = mar$df,
        lower.CL = mar$lower.CL, upper.CL = mar$upper.CL,
        p.value = mar$p.value
      ),
      it %>% mutate(Symptom = symptom, N0 = N0, N1 = N1, Nsex = Nsex)
    ) %>% mutate(AUC = auc_val, Brier = brier)
  })

# 3) BH correction within Term
logistic_res <- logistic_res %>%
  group_by(Term) %>%
  mutate(q.value = p.adjust(p.value, method = "BH")) %>%
  ungroup()

# 4) Pivot & compute ORs (per-aa and per-100-aa) for marginal slope
logit_tbl <- logistic_res %>%
  pivot_wider(
    id_cols    = c(Symptom, N0, N1, Nsex, AUC, Brier),
    names_from = Term,
    values_from= c(Estimate, SE, lower.CL, upper.CL, p.value, q.value),
    names_glue = "{Term}_{.value}"
  ) %>%
  mutate(
    OR_Marginal      = exp(MarginalSlope_Estimate),
    OR_Marginal_L95  = exp(MarginalSlope_lower.CL),
    OR_Marginal_U95  = exp(MarginalSlope_upper.CL),
    OR100_Marginal   = exp(MarginalSlope_Estimate * 100),
    OR100_Marg_L95   = exp((MarginalSlope_Estimate - 1.96 * MarginalSlope_SE) * 100),
    OR100_Marg_U95   = exp((MarginalSlope_Estimate + 1.96 * MarginalSlope_SE) * 100)
  ) %>%
  select(
    Symptom, N0, N1, Nsex, AUC, Brier,
    starts_with("FemSlope_"),
    starts_with("MaleSlope_"),
    starts_with("MarginalSlope_"),
    starts_with("OR_Marginal"),
    starts_with("OR100_Marg"),
    starts_with("Interaction_")
  )

# 5) Save
write_csv(logit_tbl, file.path(out_dir_int, "logistic_interaction_summary.csv"))
```

Plots of marginal slopes (given that we found no significant interactions):

```{r logistic-symptom-plots, message=FALSE, warning=FALSE}

library(dplyr)
library(ggplot2)
library(scales)

sex_colors   <- c(f = "#D81B60", m = "#1E88E5")


# directory
fig_logistic <- file.path(out_dir_int, "figures", "by_symptom")
dir.create(fig_logistic, recursive = TRUE, showWarnings = FALSE)

# Loop over symptoms
for (symptom in severity_symptoms) {
  df <- results_df %>%
    select(x = all_of(predictor), y = all_of(symptom), sex) %>%
    rename(predictor = x) %>%
    drop_na()

  # Skip if insufficient variation
  if (n_distinct(df$y) < 2 || nrow(df) < 10) next

  # plot
  p <- ggplot(df, aes(x = predictor, y = y)) +
    geom_point(
      aes(shape = sex, fill = sex, color = sex),
      size   = 2,
      stroke = 0.5,
      alpha  = 0.28
    ) +
    scale_shape_manual(values = c(f = 21, m = 22), labels = c("Female","Male"), name = "Sex") +
    scale_fill_manual(values = sex_colors, guide = FALSE) +
    scale_color_manual(values = sex_colors, guide = FALSE) +
    stat_smooth(
      method      = "glm",
      method.args = list(family = binomial),
      se          = TRUE,
      color       = "black",
      fill        = "grey80",
      size        = 1
    ) +
    scale_x_continuous(
      expand       = expansion(mult = c(0, 0.05)),
      limits       = c(0, NA),
      breaks       = pretty_breaks(n = 5),
      minor_breaks = pretty_breaks(n = 10)
    ) +
    scale_y_continuous(
      limits       = c(0, 1),
      breaks       = seq(0, 1, by = 0.2),
      minor_breaks = seq(0, 1, by = 0.1),
      labels       = percent_format(accuracy = 1)
    ) +
    labs(
      title = paste0(symptom, " – Pr(symptom=1) vs Protein Length"),
      x     = predictor,
      y     = "Probability (%)"
    ) +
    theme_minimal(base_size = 18, base_family = "Arial") +
    theme(
      text         = element_text(face = "bold"),
      plot.title   = element_text(size = 16, color = "black"),
      axis.title   = element_text(color = "black"),
      axis.text    = element_text(color = "black"),
      panel.grid   = element_blank(),
      axis.line    = element_line(color = "black"),
      axis.ticks   = element_line(color = "black"),
      legend.position = "none"
    )

  # save
  ggsave(
    filename = paste0("logistic_", symptom, ".png"),
    plot     = p,
    path      = fig_logistic,
    width     = 6,
    height    = 3,
    dpi       = 300
  )
}
```

Forestplot:

```{r forestplot-ProteinLength-100aa, message=FALSE, warning=FALSE}
library(dplyr)
library(ggplot2)
library(forcats)

# 1) Build forest_df from logit_tbl
forest_df <- logit_tbl %>%
  transmute(
    Symptom = Symptom,
    OR100    = OR100_Marginal,
    CI_lo    = OR100_Marg_L95,
    CI_hi    = OR100_Marg_U95,
    p.value  = MarginalSlope_p.value,
    q.value  = MarginalSlope_q.value,
    sig      = p.value < 0.05,
    Symptom  = if_else(sig, paste0(Symptom, " *"), Symptom),
    ORlabel  = sprintf("%.2f [%.2f, %.2f]", OR100, CI_lo, CI_hi),
    pqlabel  = sprintf("p=%.3f\nq=%.3f", p.value, q.value)
  ) %>%
  arrange(OR100) %>%
  mutate(Symptom = fct_rev(fct_inorder(Symptom)))

# 2) x‐axis limits
xr    <- range(forest_df$CI_lo, forest_df$CI_hi, na.rm = TRUE)
pad   <- diff(xr) * 0.15
xlims <- xr + c(-pad, pad)

# 3) Draw forest plot
p_forest_new <- ggplot(forest_df, aes(x = OR100, y = Symptom)) +
  geom_errorbarh(aes(xmin = CI_lo, xmax = CI_hi),
                 height = 0.3, color = "grey40") +
  geom_point(aes(fill = sig), shape = 21, size = 3) +
  scale_fill_manual(values = c("white", "black"), guide = FALSE) +
  geom_vline(xintercept = 1, linetype = "dashed", color = "grey60") +
  geom_text(aes(label = ORlabel),
            x = xlims[2] + 0.02 * diff(xlims),
            hjust = 0, size = 3) +
  geom_text(aes(label = pqlabel),
            x = xlims[2] + 0.18 * diff(xlims),
            hjust = 0, size = 3) +
  scale_x_continuous(limits = xlims,
                     breaks = scales::pretty_breaks(5)) +
  labs(
    title = "Effect of Protein Length on Symptom Odds (per 100 aa)",
    x     = "Odds Ratio (per 100 aa)",
    y     = NULL
  ) +
  theme_classic(base_size = 12) +
  theme(
    axis.ticks.y = element_blank(),
    axis.line.y  = element_blank(),
    axis.text.y  = element_text(size = 10),
    axis.text.x  = element_text(size = 10),
    plot.margin  = margin(5, 80, 5, 5)
  )

# 4) Save
fig_dir <- file.path(out_dir_int, "figures")
dir.create(fig_dir, recursive = TRUE, showWarnings = FALSE)
ggsave(
  filename = "forest_ProteinLength_100aa_new.png",
  plot     = p_forest_new,
  path     = fig_dir,
  width    = 8,
  height   = 0.25 * nrow(forest_df)+1,
  dpi      = 300
)
```

Standard Diagnostics:

```{r logistic-diagnostics, message=FALSE, warning=FALSE}
library(dplyr)
library(tidyr)
library(stringr)
library(ggplot2)
library(scales)
library(purrr)

predictor <- "Protein_Length_[aa]"

# guards & dirs
stopifnot(predictor %in% names(results_df))
diag_dir <- file.path(out_dir_int, "diagnostics")
dir.create(diag_dir, recursive = TRUE, showWarnings = FALSE)
glm_diag_dir <- file.path(diag_dir, "per_symptom_glm_diagnostics")
dir.create(glm_diag_dir, recursive = TRUE, showWarnings = FALSE)

# symptoms to evaluate
severity_symptoms <- var_cat %>%
  filter(Measure == "Prevalence", part_severity_score == "yes") %>%
  pull(Variable)

symptoms_exist <- severity_symptoms[severity_symptoms %in% names(results_df)]
if (length(symptoms_exist) == 0) stop("No severity-score symptoms found in results_df.")

# inclusion check per symptom
incl_tbl <- map_dfr(symptoms_exist, function(symp) {
  df <- results_df %>%
    select(y = all_of(symp), x = all_of(predictor), sex) %>%
    drop_na() %>%
    mutate(sex = factor(sex, levels = c("f","m")))

  tibble(
    Symptom = symp,
    N       = nrow(df),
    N0      = sum(df$y == 0, na.rm = TRUE),
    N1      = sum(df$y == 1, na.rm = TRUE),
    Nsex    = dplyr::n_distinct(df$sex),
    keep    = (N0 >= 10 & N1 >= 10 & Nsex == 2)
  )
})

# save skip summary
readr::write_csv(incl_tbl, file.path(diag_dir, "skip_summary.csv"))

included_syms <- incl_tbl %>% filter(keep) %>% pull(Symptom)
skipped_syms  <- incl_tbl %>% filter(!keep) %>% pull(Symptom)

# linearity-in-logit plot
if (length(included_syms) > 0) {
  diag_df <- results_df %>%
    select(all_of(c(predictor, included_syms))) %>%
    pivot_longer(cols = all_of(included_syms),
                 names_to = "Symptom", values_to = "y") %>%
    mutate(y = as.integer(y)) %>%
    drop_na()

  p <- ggplot(diag_df, aes(x = .data[[predictor]], y = y)) +
    geom_point(alpha = 0.15, size = 1, shape = 16) +
    geom_smooth(method = "glm", method.args = list(family = binomial), se = TRUE) +
    facet_wrap(~ Symptom, scales = "free_x") +
    scale_y_continuous("Symptom prevalence probability",
                       limits = c(0, 1),
                       labels = label_percent(accuracy = 1)) +
    labs(
      x     = predictor,
      title = "Linearity-in-logit check (GLM fit shown on probability scale)"
    ) +
    theme_minimal(base_size = 13) +
    theme(
      axis.title = element_text(color = "black"),
      axis.text  = element_text(color = "black"),
      strip.text = element_text(face = "bold")
    )

  ggsave(
    filename = file.path(diag_dir, "linearity-in-logit-plots.png"),
    plot     = p,
    width    = 12, height = 8, units = "in", dpi = 300
  )
}

# per-symptom GLM diagnostic panels
walk(included_syms, function(symp) {
  df <- results_df %>%
    select(y = all_of(symp), x = all_of(predictor), sex) %>%
    drop_na() %>%
    mutate(sex = factor(sex, levels = c("f","m")))

  fit <- glm(y ~ x * sex, data = df, family = binomial)

  png(
    filename = file.path(glm_diag_dir, paste0(symp, "_glm_diagnostics.png")),
    width = 10, height = 10, units = "in", res = 300, type = "cairo"
  )
  par(mfrow = c(2, 2), oma = c(0, 0, 3, 0), mar = c(5, 4, 2, 1))
  plot(fit, which = 1, main = "Residuals vs Fitted", caption = "", sub.caption = "", ask = FALSE)
  plot(fit, which = 2, main = "Normal Q–Q (Std. deviance residuals)", caption = "", sub.caption = "", ask = FALSE)
  plot(fit, which = 4, main = "Cook's Distance", caption = "", sub.caption = "", ask = FALSE)
  plot(fit, which = 5, main = "Residuals vs Leverage (Cook's contours)", caption = "", sub.caption = "", ask = FALSE)
  mtext(paste("Logistic diagnostics for:", symp), side = 3, outer = TRUE, line = 1.2, font = 2, cex = 1.1)
  dev.off()
})

# summary
message("Diagnostics — included: ", length(included_syms),
        " | skipped: ", length(skipped_syms),
        " (see skip_summary.csv for details)")

```

### gnomAD versus SYS individuals

```{r write_gnomad_vs_patients_excel, echo=TRUE, message=FALSE, warning=FALSE}
library(dplyr)
library(readr)
library(tidyr)
library(purrr)
library(writexl)

gnomad_dir <- file.path(data_dir, "gnomAD comparison")

# 1) Load MAP results for gnomAD population
gnomad <- read_csv(
  file.path(data_dir, "MAP_results_gnomAD_without_UTRs.csv"),
  show_col_types = FALSE
) %>%
  rename(
    Mutation_Type              = `Mutation Type`,
    Domain_Location_Of_Variant = `Domain Location Of Variant`,
    Lost_Functional_Domains    = `Lost Functional Domains`,
    lost_signals               = `Lost Motifs`,
    `Protein_Length_[aa]`      = `Protein Length aa`
  )

# 2) Ensure patient df has Protein Length column
if (!"Protein_Length_[aa]" %in% names(results_df)) {
  stop("Patient data.frame needs a column called Protein_Length_[aa]")
}

# 3) filtering
clinvar_keep <- c(
  "Uncertain significance",
  "Benign",
  "Likely benign",
  "Benign/Likely benign"
)
exclude_types <- c("Silent", "Missense", "In-Frame indel")

# 4) Build four subsets
gnomad_orig   <- gnomad %>% filter(ClinVar.Germline.Classification %in% clinvar_keep)
gnomad_filt   <- gnomad_orig %>% filter(!Mutation_Type %in% exclude_types)

patients_orig <- results_df
patients_filt <- patients_orig %>% filter(!Mutation_Type %in% exclude_types)

# 5) Variables to summarise
cat_vars <- c(
  "Mutation_Type",
  "Domain_Location_Of_Variant",
  "Lost_Functional_Domains",
  "lost_signals"
)
cont_var <- "Protein_Length_[aa]"

# 6) Summaries
summ_cat <- function(df, var) {
  df %>%
    mutate(!!sym(var) := replace_na(.data[[var]], "none")) %>%
    count(Category = .data[[var]], name = "Count") %>%
    mutate(Percent = round(Count / sum(Count) * 100, 1))
}

summ_cont <- function(df, var) {
  x <- df[[var]]
  tibble(
    Metric = c("n", "Mean", "SD", "Median", "IQR", "Min", "Max"),
    Value  = c(
      sum(!is.na(x)),
      mean(x,    na.rm = TRUE),
      sd(x,      na.rm = TRUE),
      median(x,  na.rm = TRUE),
      stats::IQR(x,     na.rm = TRUE),   
      min(x,     na.rm = TRUE),
      max(x,     na.rm = TRUE)
    )
  )
}

# 7) Build sheet list
sheets <- list()

# 7a) categorical sheets
for (v in cat_vars) {
  g_o <- summ_cat(gnomad_orig,   v) %>% rename_with(~paste0("Gnomad_Orig_", .), c("Count","Percent"))
  g_f <- summ_cat(gnomad_filt,   v) %>% rename_with(~paste0("Gnomad_Filt_", .), c("Count","Percent"))
  p_o <- summ_cat(patients_orig, v) %>% rename_with(~paste0("Patient_Orig_", .), c("Count","Percent"))
  p_f <- summ_cat(patients_filt, v) %>% rename_with(~paste0("Patient_Filt_", .), c("Count","Percent"))
  
  cat_df <- list(g_o, g_f, p_o, p_f) %>%
    reduce(full_join, by = "Category") %>%
    arrange(desc(if_any(starts_with("Gnomad_Orig_Count"), ~ . > 0)))
  
  sheets[[paste0(v, "_categorical")]] <- cat_df
}

# 7b) continuous sheet
c_go <- summ_cont(gnomad_orig,   cont_var) %>% rename(Gnomad_Orig  = Value)
c_gf <- summ_cont(gnomad_filt,   cont_var) %>% rename(Gnomad_Filt  = Value)
c_po <- summ_cont(patients_orig, cont_var) %>% rename(Patient_Orig = Value)
c_pf <- summ_cont(patients_filt, cont_var) %>% rename(Patient_Filt = Value)

sheets[["Protein_Length_continuous"]] <-
  list(c_go, c_gf, c_po, c_pf) %>%
  reduce(full_join, by = "Metric")

# 8) Write Excel
out_file <- file.path(tables_dir, "gnomad_vs_results_comparison.xlsx")
write_xlsx(sheets, path = out_file)
message("✔ Written: ", out_file)
```

### Lethal versus non-lethal cases

```{r write_lethality_comparison, echo=TRUE, message=FALSE, warning=FALSE}
library(dplyr)
library(tidyr)
library(purrr)
library(writexl)

# ensure death is 0/1 and drop NAs
patients <- results_df %>%
  mutate(death = as.integer(death)) %>%
  filter(death %in% c(0,1))

nonlethal <- patients %>% filter(death == 0)
lethal    <- patients %>% filter(death == 1)

# variables to summarise
cat_vars <- c(
  "Mutation_Type",
  "Domain_Location_Of_Variant",
  "Lost_Functional_Domains",
  "lost_signals"
)
cont_var <- "Protein_Length_[aa]"

# helpers
summ_cat <- function(df, var) {
  df %>%
    mutate(!!sym(var) := replace_na(.data[[var]], "none")) %>%
    count(Category = .data[[var]], name = "Count") %>%
    mutate(Percent = round(Count / sum(Count) * 100, 1))
}

summ_cont <- function(df, var) {
  x <- df[[var]]
  tibble(
    Metric = c("n", "Mean", "SD", "Median", "IQR", "Min", "Max"),
    Value  = c(
      sum(!is.na(x)),
      mean(x,    na.rm = TRUE),
      sd(x,      na.rm = TRUE),
      median(x,  na.rm = TRUE),
      IQR(x,     na.rm = TRUE),
      min(x,     na.rm = TRUE),
      max(x,     na.rm = TRUE)
    )
  )
}

# build sheets list
sheets_leth <- list()

# categorical
for (v in cat_vars) {
  nl <- summ_cat(nonlethal, v) %>%
    rename(NonLethal_Count   = Count,
           NonLethal_Percent = Percent)
  lt <- summ_cat(lethal,    v) %>%
    rename(Lethal_Count      = Count,
           Lethal_Percent    = Percent)
  df_join <- full_join(nl, lt, by = "Category") %>%
    arrange(desc(replace_na(NonLethal_Count, 0)))
  sheets_leth[[paste0(v, "_lethality_categorical")]] <- df_join
}

# continuous
c_nl <- summ_cont(nonlethal, cont_var) %>%
  rename(NonLethal = Value)
c_lt <- summ_cont(lethal,    cont_var) %>%
  rename(Lethal    = Value)

sheets_leth[["Protein_Length_lethality_continuous"]] <-
  list(c_nl, c_lt) %>%
  reduce(full_join, by = "Metric")

# 5) write Excel 
out_file <- file.path(tables_dir, "results_lethality_comparison.xlsx")
write_xlsx(sheets_leth, path = out_file)
message("✔ Written: ", out_file)
```

# Miscellaneous

## Figure 1C: Target Plot

```{r target-plot}
library(tidyverse)
library(ggforce)
library(grid)

# 1. Load data
df <- results_df %>%
  transmute(
    patient_ID,
    `motor delay`          = as.numeric(`DD_(motor_delay)`),
    `delayed speech`       = as.numeric(`DD_(speech_delay)`),
    ID                     = as.numeric(`ID_(any)`),
    hypotonia              = as.numeric(muscular_hypotonia),
    `feeding difficulties` = as.numeric(feeding_difficulties_except_hyperphagia),
    hyperphagia            = as.numeric(hyperphagia),
    overweight             = as.numeric(overweight_issues),
    underweight            = as.numeric(underweight_issues),
    `chronic constipation` = as.numeric(chronic_constipation),
    GERD                   = as.numeric(GERD),
    `sleep apnea`          = as.numeric(sleep_apnea),
    `respiratory distress` = as.numeric(respiratory_distress),
    contractures           = as.numeric(contractures_or_arthrogryposis),
    scoliosis              = as.numeric(scoliosis_or_kyphosis),
    epilepsy               = as.numeric(seizures_or_epilepsy),
    `ocular issues`        = as.numeric(ocular_anomalies),
    `genitourinary issues` = as.numeric(genitourinary_anomalies),
    `GH deficiency`        = as.numeric(GH_deficiency),
    `endocrine issues`     = as.numeric(`endocrine_or_metabolic_dysfunction_(any)`),
    autism                 = as.numeric(autism),
    anxiety                = as.numeric(anxiety),
    `other behavioral issues` = as.numeric(temper_tantrums_or_impulsivity),
    points_achieved        = rowSums(across(`motor delay`:`other behavioral issues`), na.rm = TRUE),
    `max achievable points` = as.numeric(max_achievable_points),
    severity_score          = as.numeric(severity)
  )

# 2. Pivot long + mark missing + compute S_part and S_score
symptom_cols <- setdiff(names(df),
                        c("patient_ID","points_achieved","max achievable points","severity_score"))
long_A <- df %>%
  pivot_longer(all_of(symptom_cols),
               names_to  = "symptom",
               values_to = "symptom_points") %>%
  group_by(patient_ID) %>%
  mutate(
    missing        = is.na(symptom_points),
    symptom_points = replace_na(symptom_points, 0),
    total_pts      = sum(symptom_points),
    S_part         = if_else(total_pts == 0, 0, symptom_points/total_pts * severity_score),
    S_score        = severity_score
  ) %>%
  ungroup() %>%
  filter(!is.na(S_score))

# 3. Keep only symptoms ever present
present_syms <- long_A %>%
  group_by(symptom) %>%
  summarise(any_present = any(S_part > 0), .groups = "drop") %>%
  filter(any_present) %>%
  pull(symptom)
long_A <- filter(long_A, symptom %in% present_syms)

# 4. Geometry constants
n_pat    <- n_distinct(long_A$patient_ID)
symptoms <- rev(unique(long_A$symptom))
n_sym    <- length(symptoms)
max_S    <- max(long_A$S_score)
inner_r  <- max_S * 0.10
ring_thk <- (max_S * 0.80) / (n_sym + 1)
outer_R  <- inner_r + (n_sym + 1) * ring_thk

# 5. Label positions
buffer   <- outer_R * 0.02
labels_df <- tibble(symptom = symptoms, ridx = seq_along(symptoms)) %>%
  mutate(
    r_mid       = inner_r + (ridx - 0.5) * ring_thk,
    col         = ridx %% 2,
    x_line_end  = if_else(col == 0,
                          outer_R * 1.05 - buffer,
                          outer_R * 1.65 - buffer),
    x_text      = if_else(col == 0,
                          outer_R * 1.05,
                          outer_R * 1.65),
    y_line_end  = r_mid,
    y_text      = r_mid,
    hjust       = 0
  )

# -------------------------------------------------------------------
# Plot A: sorted by ascending overall severity score
# -------------------------------------------------------------------
# 6A. Order patients by severity
patient_order_sev <- long_A %>%
  distinct(patient_ID, S_score) %>%
  arrange(S_score, patient_ID) %>%
  pull(patient_ID)

long_sev <- long_A %>%
  mutate(patient_ID = factor(patient_ID, levels = patient_order_sev))

# 7A. Build ring & outer-ring data for severity order
sym_df_sev <- long_sev %>%
  group_by(patient_ID, symptom) %>%
  summarise(
    missing = missing[1],
    S_part  = sum(S_part),
    S_score = S_score[1],
    .groups = "drop"
  ) %>%
  arrange(factor(symptom, levels = symptoms)) %>%
  mutate(
    ridx    = as.integer(factor(symptom, levels = symptoms)),
    r0      = inner_r + (ridx - 1) * ring_thk,
    r1      = inner_r + ridx     * ring_thk,
    idx     = as.integer(patient_ID) - 1,
    start   = 2 * pi * idx / n_pat,
    end     = 2 * pi * (idx + 1) / n_pat,
    present = S_part > 0
  )
outer_sev <- sym_df_sev %>%
  distinct(patient_ID, S_score, .keep_all = TRUE) %>%
  mutate(
    r0 = inner_r + n_sym     * ring_thk,
    r1 = inner_r + (n_sym+1) * ring_thk
  )

# 8A. Build severity‐ordered plot
p_sev <- ggplot() +
  geom_arc_bar(data = filter(sym_df_sev, missing),
               aes(x0=0, y0=0, r0=r0, r=r1, start=start, end=end),
               fill="grey80", colour=NA) +
  geom_arc_bar(data = filter(sym_df_sev, present),
               aes(x0=0, y0=0, r0=r0, r=r1, start=start, end=end),
               fill="black", colour=NA) +
  geom_arc_bar(data = sym_df_sev,
               aes(x0=0, y0=0, r0=r0, r=r1, start=start, end=end),
               fill=NA, colour="grey80", size=0.2) +
  geom_arc_bar(data = outer_sev,
               aes(x0=0, y0=0, r0=r0, r=r1, start=start, end=end, fill=S_score),
               colour="white", size=0.3) +
  scale_fill_gradientn(
    name    = "Severity S",
    colours = c("#B5E3C6", "#49B4C5", "#244A71"),
    limits  = c(0, 1),
    guide   = guide_colourbar(
      direction = "horizontal",
      barwidth  = unit(8,  "cm"),
      barheight = unit(1,  "cm")
    )
  ) +
  geom_segment(data = labels_df,
               aes(x=0, y=r_mid, xend=x_line_end, yend=y_line_end),
               colour="grey30", linetype="dotted", size=0.8) +
  geom_text(data = labels_df,
            aes(x=x_text, y=y_text, label=symptom, hjust=hjust),
            family="Helvetica", fontface="bold", size=8, colour="black") +
  coord_fixed(xlim = c(-outer_R, outer_R*1.6),
              ylim = c(-outer_R, outer_R),
              expand = FALSE, clip = "off") +
  theme_void() +
  theme(
    legend.position   = c(0.85, 0.10),
    legend.direction  = "horizontal",
    legend.background = element_rect(fill="white", colour=NA),
    plot.margin       = margin(5.5, 90, 5.5, 5.5)
  )

# -------------------------------------------------------------------
# Plot B: sorted by Locus
# -------------------------------------------------------------------
# 6B. Order patients by Locus
patient_order_loc <- results_df %>%
  distinct(patient_ID, Locus) %>%
  filter(patient_ID %in% long_A$patient_ID) %>%
  arrange(Locus, patient_ID) %>%
  pull(patient_ID)

long_loc <- long_A %>%
  mutate(patient_ID = factor(patient_ID, levels = patient_order_loc))

# 7B. Build ring & outer‐ring data for locus order
sym_df_loc <- long_loc %>%
  group_by(patient_ID, symptom) %>%
  summarise(
    missing = missing[1],
    S_part  = sum(S_part),
    S_score = S_score[1],
    .groups = "drop"
  ) %>%
  arrange(factor(symptom, levels = symptoms)) %>%
  mutate(
    ridx  = as.integer(factor(symptom, levels = symptoms)),
    r0    = inner_r + (ridx - 1) * ring_thk,
    r1    = inner_r + ridx     * ring_thk,
    idx   = as.integer(patient_ID) - 1,
    start = 2 * pi * idx / n_pat,
    end   = 2 * pi * (idx + 1) / n_pat,
    present = S_part > 0
  )
outer_loc <- sym_df_loc %>%
  distinct(patient_ID, S_score, .keep_all = TRUE) %>%
  mutate(
    r0 = inner_r + n_sym     * ring_thk,
    r1 = inner_r + (n_sym+1) * ring_thk
  )

# 8B. Build locus‐ordered plot
p_loc <- ggplot() +
  geom_arc_bar(data = filter(sym_df_loc, missing),
               aes(x0=0, y0=0, r0=r0, r=r1, start=start, end=end),
               fill="grey80", colour=NA) +
  geom_arc_bar(data = filter(sym_df_loc, present),
               aes(x0=0, y0=0, r0=r0, r=r1, start=start, end=end),
               fill="black", colour=NA) +
  geom_arc_bar(data = sym_df_loc,
               aes(x0=0, y0=0, r0=r0, r=r1, start=start, end=end),
               fill=NA, colour="grey80", size=0.2) +
  geom_arc_bar(data = outer_loc,
               aes(x0=0, y0=0, r0=r0, r=r1, start=start, end=end, fill=S_score),
               colour="white", size=0.3) +
  scale_fill_gradientn(
    name    = "Severity S",
    colours = c("#B5E3C6", "#49B4C5", "#244A71"),
    limits  = c(0, 1),
    guide   = guide_colourbar(
      direction = "horizontal",
      barwidth  = unit(8,  "cm"),
      barheight = unit(1,  "cm")
    )
  ) +
  geom_segment(data = labels_df,
               aes(x=0, y=r_mid, xend=x_line_end, yend=y_line_end),
               colour="grey30", linetype="dotted", size=0.8) +
  geom_text(data = labels_df,
            aes(x=x_text, y=y_text, label=symptom, hjust=hjust),
            family="Helvetica", fontface="bold", size=8, colour="black") +
  coord_fixed(xlim = c(-outer_R, outer_R*1.6),
              ylim = c(-outer_R, outer_R),
              expand = FALSE, clip = "off") +
  theme_void() +
  theme(
    legend.position   = c(0.85, 0.10),
    legend.direction  = "horizontal",
    legend.background = element_rect(fill="white", colour=NA),
    plot.margin       = margin(5.5, 90, 5.5, 5.5)
  )

print(p_sev)
print(p_loc)

# 10. Save 
ggsave(
  filename = file.path(output_dir, "plots/target_plot_by_severity_new.png"),
  plot     = p_sev,
  width    = 25, height = 12,
  dpi      = 1200,
  bg       = "white"
)
ggsave(
  filename = file.path(output_dir, "plots/target_plot_by_severity_new.svg"),
  plot     = p_sev,
  width    = 25, height = 12,
  device   = "svg",
  dpi      = 1200,
  bg       = "white"
)
ggsave(
  filename = file.path(output_dir, "plots/target_plot_by_locus_new.png"),
  plot     = p_loc,
  width    = 25, height = 12,
  dpi      = 1200,
  bg       = "white"
)
ggsave(
  filename = file.path(output_dir, "plots/target_plot_by_locus_new.svg"),
  plot     = p_loc,
  width    = 25, height = 12,
  device   = "svg",
  dpi      = 1200,
  bg       = "white"
)
```

```{r new figure-1-c-complexheatmap}
library(tidyverse)
library(ComplexHeatmap)
library(circlize)
library(grid)

# Minimum number of individuals with symptom present
min_n <- 0

# Build clean patient x symptom table
df_heat <- results_df %>%
  transmute(
    patient_ID,
    severity_score = as.numeric(severity),
    `motor delay` = as.numeric(`DD_(motor_delay)`),
    `delayed speech` = as.numeric(`DD_(speech_delay)`),
    `intellectual disability` = as.numeric(`ID_(any)`),
    hypotonia = as.numeric(muscular_hypotonia),
    `feeding difficulties` = as.numeric(feeding_difficulties_except_hyperphagia),
    hyperphagia = as.numeric(hyperphagia),
    overweight = as.numeric(overweight_issues),
    underweight = as.numeric(underweight_issues),
    `chronic constipation` = as.numeric(chronic_constipation),
    GERD = as.numeric(GERD),
    `sleep apnea` = as.numeric(sleep_apnea),
    `respiratory distress` = as.numeric(respiratory_distress),
    contractures = as.numeric(contractures_or_arthrogryposis),
    scoliosis = as.numeric(scoliosis_or_kyphosis),
    epilepsy = as.numeric(seizures_or_epilepsy),
    `ocular issues` = as.numeric(ocular_anomalies),
    `genitourinary issues` = as.numeric(genitourinary_anomalies),
    `GH deficiency` = as.numeric(GH_deficiency),
    `endocrine issues` = as.numeric(`endocrine_or_metabolic_dysfunction_(any)`),
    autism = as.numeric(autism),
    anxiety = as.numeric(anxiety),
    `other behavioral issues` = as.numeric(temper_tantrums_or_impulsivity)
  ) %>%
  filter(!is.na(severity_score)) %>%
  arrange(severity_score, patient_ID)

# Determine symptom columns and filter by prevalence
symptom_cols_all <- setdiff(
  names(df_heat),
  c("patient_ID", "severity_score")
)

present_counts <- df_heat %>%
  summarise(across(all_of(symptom_cols_all), ~ sum(.x == 1, na.rm = TRUE))) %>%
  pivot_longer(everything(), names_to = "symptom", values_to = "n_present")

symptom_cols <- present_counts %>%
  filter(n_present >= min_n) %>%
  pull(symptom)

# Matrix for ComplexHeatmap (discrete 0/1 + NA mapping)
mat <- df_heat %>%
  select(all_of(symptom_cols)) %>%
  as.matrix()

rownames(mat) <- df_heat$patient_ID

mat <- apply(mat, c(1, 2), function(x) {
  if (is.na(x)) {
    return(NA_character_)
  }
  as.character(as.integer(x))
})
sev <- df_heat$severity_score

rng <- range(sev, na.rm = TRUE)
mid <- mean(rng)

col_sev <- colorRamp2(
  c(rng[1], mid, rng[2]),
  c("#005F73", "white", "#AE2012")
)


row_ha <- rowAnnotation(
  severity = sev,
  col = list(severity = col_sev),
  annotation_name_side = "top",
  width = unit(6, "mm")
)

col_sym <- c(
  "0" = "#005F73",
  "1" = "#AE2012"
)

ht <- Heatmap(
  mat,
  name = "symptoms",
  col = col_sym,
  na_col = "#F7F5F1",
  cluster_rows = FALSE,
  cluster_columns = FALSE,
  show_row_names = FALSE,
  show_column_names = TRUE,
  column_names_rot = 45,
  column_names_gp = grid::gpar(fontsize = 8),
  rect_gp = gpar(col = NA),
  right_annotation = row_ha,
  heatmap_legend_param = list(
    at = c("0", "1"),
    labels = c("absent", "present")
  )
)

draw(ht)

heatmap_out_dir <- file.path(output_dir, "plots")
dir.create(heatmap_out_dir, recursive = TRUE, showWarnings = FALSE)

pdf(
  file = file.path(heatmap_out_dir, "target_heatmap_by_severity_complexheatmap.pdf"),
  width = 4,
  height = 3,
  bg = "transparent"
)

draw(ht)

dev.off()
```

## Figure 3C: Severity density across MAGEL2

```{r 2D-Severity-Density-and-Death-Plot}

library(dplyr)
library(tidyr)
library(ggplot2)
library(viridis)

# Define domains in bp positions
domains_bp <- list(
  proline_rich = c(1,       819 * 3),
  U7BS         = c(820 * 3, 1027 * 3),
  U7BS_MHD     = c(1028 * 3, 1034 * 3),
  MHD          = c(1035 * 3, 1195 * 3),
  after_MHD    = c(1196 * 3, Inf)
)

# 1 data prep
# 1a. Severity points 
raw_df <- results_df %>%
  select(Locus, severity, sex) %>%
  drop_na(severity, Locus)

# 1b. Death-only points 
death_df <- results_df %>%
  filter(death == 1) %>%
  select(Locus, sex)

death_y <- 1.17

# 2. Build plot
p2d <- ggplot(raw_df, aes(x = Locus, y = severity)) +
  
  # A) Domain shading
  annotate("rect",
           xmin = domains_bp$proline_rich[1], xmax = domains_bp$proline_rich[2],
           ymin = -Inf, ymax = Inf,
           fill = "#E69F00", alpha = 0.5
  ) +
  annotate("rect",
           xmin = domains_bp$U7BS[1], xmax = domains_bp$U7BS[2],
           ymin = -Inf, ymax = Inf,
           fill = "#66B2FF", alpha = 0.5
  ) +
  annotate("rect",
           xmin = domains_bp$U7BS_MHD[1], xmax = domains_bp$U7BS_MHD[2],
           ymin = -Inf, ymax = Inf,
           fill = "#009E73", alpha = 0.4
  ) +
  annotate("rect",
           xmin = domains_bp$MHD[1], xmax = domains_bp$MHD[2],
           ymin = -Inf, ymax = Inf,
           fill = "#99CC66", alpha = 0.5
  ) +
  annotate("rect",
           xmin = domains_bp$after_MHD[1], xmax = domains_bp$after_MHD[2],
           ymin = -Inf, ymax = Inf,
           fill = "#CC79A7", alpha = 0.2
  ) +
  
  # B) 2D density polygons
  stat_density2d(
    aes(fill = ..level..),
    geom    = "polygon",
    contour = TRUE,
    n       = 200,
    bins    = 20
  ) +

  # C) severity points
  geom_point(
    aes(shape = sex),
    fill    = "black",
    color   = "white",
    size    = 2,
    stroke  = 1,
    alpha   = 0.2
  ) +

  # D) Death markers
  geom_point(
    data        = death_df,
    aes(x = Locus, y = death_y, shape = sex),
    fill        = "#DC3220",
    color       = "#DC3220",
    size        = 2,
    stroke      = 1,
    alpha       = 0.2,
    inherit.aes = FALSE
  ) +

  # E) Shape mapping for sex-specific shapes
  scale_shape_manual(values = c(f = 21, m = 22)) +

  # F) Density fill scale
  scale_fill_viridis_c(
    option    = "inferno",
    direction = -1,
    name      = "Density"
  ) +

  # G) X-axis
  scale_x_continuous(
    limits = c(0, NA),
    expand = expansion(mult = c(0, 0.02)),
    breaks = scales::pretty_breaks(n = 5)
  ) +

  # H) Y-axis
  scale_y_continuous(
    limits = c(0, 1.2),
    expand = expansion(mult = c(0, 0.02)),
    breaks = scales::pretty_breaks(n = 7)
  ) +

  # I) Labels
  labs(
    title = "2D Density of Severity Across Locus Positions\n(with Death Events by Sex)",
    x     = "Locus (cDNA base position)",
    y     = "Severity"
  ) +

  # J) Theme
  theme_minimal(base_family = "Arial", base_size = 22) +
  theme(
    panel.grid    = element_blank(),
    axis.line     = element_line(color = "black"),
    axis.ticks    = element_line(color = "black"),
    plot.title    = element_text(face = "bold", size = 16, hjust = 0.5),
    axis.text     = element_text(face = "bold", color = "black"),
    axis.title    = element_text(face = "bold", color = "black"),
    legend.title  = element_text(face = "bold"),
    legend.text   = element_text(face = "bold")
  )

print(p2d)

# 3. Save
density_dir <- file.path(plots_dir, "density plot")
dir.create(density_dir, recursive = TRUE, showWarnings = FALSE)
ggsave(
  filename = file.path(density_dir, "severity_Locus_2d_density_domains_with_deaths_by_sex.png"),
  plot     = p2d,
  device   = "png",
  dpi      = 300,
  width    = 8,
  height   = 5
)
```

```{r new 2D-Severity-Density-and-Death-Plot}

library(dplyr)
library(tidyr)
library(ggplot2)
library(viridis)

# Define domains in bp positions
domains_bp <- list(
  proline_rich = c(1,       819 * 3),
  U7BS         = c(820 * 3, 1027 * 3),
  U7BS_MHD     = c(1028 * 3, 1034 * 3),
  MHD          = c(1035 * 3, 1195 * 3),
  after_MHD    = c(1196 * 3, Inf)
)

# Data prep
raw_df <- results_df %>%
  select(Locus, severity, sex) %>%
  drop_na(severity, Locus, sex) %>%
  mutate(sex = tolower(sex))

death_df <- results_df %>%
  filter(death == 1) %>%
  select(Locus, sex) %>%
  drop_na(Locus, sex) %>%
  mutate(sex = tolower(sex))

death_y <- 1.17

p2d_clean_shapes <- ggplot(raw_df, aes(x = Locus, y = severity)) +
  annotate("rect",
           xmin = domains_bp$proline_rich[1], xmax = domains_bp$proline_rich[2],
           ymin = -Inf, ymax = Inf, fill = "#E69F00", alpha = 0.5) +
  annotate("rect",
           xmin = domains_bp$U7BS[1], xmax = domains_bp$U7BS[2],
           ymin = -Inf, ymax = Inf, fill = "#66B2FF", alpha = 0.5) +
  annotate("rect",
           xmin = domains_bp$U7BS_MHD[1], xmax = domains_bp$U7BS_MHD[2],
           ymin = -Inf, ymax = Inf, fill = "#009E73", alpha = 0.4) +
  annotate("rect",
           xmin = domains_bp$MHD[1], xmax = domains_bp$MHD[2],
           ymin = -Inf, ymax = Inf, fill = "#99CC66", alpha = 0.5) +
  annotate("rect",
           xmin = domains_bp$after_MHD[1], xmax = domains_bp$after_MHD[2],
           ymin = -Inf, ymax = Inf, fill = "#CC79A7", alpha = 0.2) +
  stat_density2d(
    aes(fill = ..level..),
    geom    = "polygon",
    contour = TRUE,
    n       = 200,
    bins    = 20
  ) +
  geom_point(
    aes(shape = sex),
    color = "black",
    size  = 1.8,
    alpha = 0.35
  ) +
  geom_point(
    data        = death_df,
    aes(x = Locus, y = death_y, shape = sex),
    color       = "#DC3220",
    size        = 2.2,
    alpha       = 0.9,
    inherit.aes = FALSE
  ) +
  scale_shape_manual(values = c(f = 16, m = 15)) +
  scale_fill_viridis_c(option = "inferno", direction = -1, name = "Density") +
  scale_x_continuous(
    limits = c(0, NA),
    expand = expansion(mult = c(0, 0.02)),
    breaks = scales::pretty_breaks(n = 5)
  ) +
  scale_y_continuous(
    limits = c(0, 1.2),
    expand = expansion(mult = c(0, 0.02)),
    breaks = scales::pretty_breaks(n = 7)
  ) +
  labs(
    title = "2D Density of Severity Across Locus Positions\n(with Death Events by Sex)",
    x     = "Locus (cDNA base position)",
    y     = "Severity"
  ) +
  theme_minimal(base_family = "Arial", base_size = 22) +
  theme(
    panel.grid   = element_blank(),
    axis.line    = element_line(color = "black"),
    axis.ticks   = element_line(color = "black"),
    plot.title   = element_text(face = "bold", size = 16, hjust = 0.5),
    axis.text    = element_text(face = "bold", color = "black"),
    axis.title   = element_text(face = "bold", color = "black"),
    legend.title = element_text(face = "bold"),
    legend.text  = element_text(face = "bold")
  )

print(p2d_clean_shapes)

# Save as PDF
density_dir <- file.path(plots_dir, "density plot")
dir.create(density_dir, recursive = TRUE, showWarnings = FALSE)
ggsave(
  filename = file.path(density_dir, "severity_Locus_2d_density_domains_with_deaths_by_sex_clean_shapes.pdf"),
  plot     = p2d_clean_shapes,
  device   = grDevices::cairo_pdf,
  width    = 8,
  height   = 5
)
```

## Figure 3D: Mixed-type association heatmap (selected protein properties)

```{r mixed-association-heatmap-selected-vars, fig.width=9, fig.height=8, message=FALSE, warning=FALSE}
library(dplyr)
library(tidyr)
library(ComplexHeatmap)
library(circlize)
library(grid)

# Variables requested for the mixed-type association heatmap
selected_features <- c(
  "Protein_Length_[aa]",
  "Lost_Functional_Domains",
  "lost_signals"
)

assoc_df <- results_df %>%
  select(all_of(selected_features)) %>%
  mutate(
    across(where(is.character), ~ na_if(trimws(.x), "")),
    across(where(is.character), as.factor)
  )

to_factor_clean <- function(x) {
  if (is.factor(x)) return(droplevels(x))
  factor(as.character(x))
}

cramers_v <- function(x, y) {
  ok <- complete.cases(x, y)
  x <- x[ok]
  y <- y[ok]
  if (length(x) < 3) return(NA_real_)

  tab <- table(to_factor_clean(x), to_factor_clean(y))
  n <- sum(tab)
  if (n == 0) return(NA_real_)
  if (nrow(tab) < 2 || ncol(tab) < 2) return(NA_real_)

  chi <- suppressWarnings(chisq.test(tab, correct = FALSE)$statistic)
  if (is.na(chi)) return(NA_real_)
  phi2 <- as.numeric(chi) / n
  k <- min(nrow(tab) - 1, ncol(tab) - 1)
  if (k <= 0) return(NA_real_)
  sqrt(phi2 / k)
}

eta_squared <- function(x_num, y_cat) {
  ok <- complete.cases(x_num, y_cat)
  x_num <- x_num[ok]
  y_cat <- y_cat[ok]
  if (length(x_num) < 3) return(NA_real_)

  y_cat <- to_factor_clean(y_cat)
  if (nlevels(y_cat) < 2) return(NA_real_)
  if (sd(x_num) == 0) return(NA_real_)

  fit <- tryCatch(lm(x_num ~ y_cat), error = function(e) NULL)
  if (is.null(fit)) return(NA_real_)

  aov_tab <- anova(fit)
  ss_between <- aov_tab$`Sum Sq`[1]
  ss_total <- sum(aov_tab$`Sum Sq`)
  if (is.na(ss_between) || is.na(ss_total) || ss_total == 0) return(NA_real_)
  max(0, min(1, ss_between / ss_total))
}

assoc_value <- function(x, y, tx, ty) {
  if (tx == "continuous" && ty == "continuous") {
    ok <- complete.cases(x, y)
    if (sum(ok) < 3) return(NA_real_)
    r <- suppressWarnings(cor(x[ok], y[ok], method = "spearman"))
    return(abs(as.numeric(r)))
  }

  if (tx == "continuous" && ty == "categorical") {
    return(eta_squared(as.numeric(x), y))
  }

  if (ty == "continuous" && tx == "categorical") {
    return(eta_squared(as.numeric(y), x))
  }

  if (tx == "categorical" && ty == "categorical") {
    return(cramers_v(x, y))
  }

  NA_real_
}

feature_types <- c(
  "Protein_Length_[aa]" = "continuous",
  "Lost_Functional_Domains" = "categorical",
  "lost_signals" = "categorical"
)

# Basic validation: categorical vars need at least two observed levels
cat_vars <- names(feature_types)[feature_types == "categorical"]
for (v in cat_vars) {
  n_lvl <- nlevels(to_factor_clean(assoc_df[[v]][!is.na(assoc_df[[v]])]))
  if (n_lvl < 2) stop(paste0("Categorical variable '", v, "' has fewer than two observed levels."))
}

cont_vars <- names(feature_types)[feature_types == "continuous"]
for (v in cont_vars) {
  if (sum(!is.na(assoc_df[[v]])) < 3) stop(paste0("Continuous variable '", v, "' has too few non-missing values."))
}

p <- length(selected_features)
assoc_mat <- matrix(NA_real_, nrow = p, ncol = p, dimnames = list(selected_features, selected_features))

for (i in seq_len(p)) {
  assoc_mat[i, i] <- 1
  if (i < p) {
    for (j in (i + 1):p) {
      vi <- selected_features[i]
      vj <- selected_features[j]
      xi <- assoc_df[[vi]]
      xj <- assoc_df[[vj]]
      aij <- assoc_value(xi, xj, feature_types[vi], feature_types[vj])
      assoc_mat[i, j] <- aij
      assoc_mat[j, i] <- aij
    }
  }
}

assoc_for_cluster <- assoc_mat
assoc_for_cluster[is.na(assoc_for_cluster)] <- 0

dist_mat <- as.dist(1 - assoc_for_cluster)
hc <- hclust(dist_mat, method = "average")

type_cols <- c(
  continuous = "#1f78b4",
  categorical = "#ff7f00"
)

ha_top <- HeatmapAnnotation(
  `Feature type` = factor(feature_types[colnames(assoc_mat)], levels = c("continuous", "categorical")),
  col = list(`Feature type` = type_cols),
  annotation_name_gp = gpar(fontsize = 9, fontface = "bold")
)

ha_row <- rowAnnotation(
  `Feature type` = factor(feature_types[rownames(assoc_mat)], levels = c("continuous", "categorical")),
  col = list(`Feature type` = type_cols),
  annotation_name_gp = gpar(fontsize = 9, fontface = "bold")
)

col_fun <- colorRamp2(c(0, 1), c("white", "black"))

ht <- Heatmap(
  assoc_mat,
  name = "Association\nstrength",
  col = col_fun,
  na_col = "#f0f0f0",
  rect_gp = gpar(col = "white", lwd = 1),
  cluster_rows = as.dendrogram(hc),
  cluster_columns = as.dendrogram(hc),
  show_row_dend = TRUE,
  show_column_dend = TRUE,
  row_names_gp = gpar(fontsize = 9),
  column_names_gp = gpar(fontsize = 9),
  column_names_rot = 45,
  top_annotation = ha_top,
  right_annotation = ha_row,
  heatmap_legend_param = list(at = c(0, 0.25, 0.5, 0.75, 1)),
  cell_fun = function(j, i, x, y, width, height, fill) {
    value <- assoc_mat[i, j]
    if (is.finite(value)) {
      grid.text(sprintf("%.2f", value), x, y, gp = gpar(fontsize = 9, col = "white", fontface = "bold"))
    }
  }
)

draw(ht)

assoc_dir <- file.path(plots_dir, "association_heatmap")
dir.create(assoc_dir, recursive = TRUE, showWarnings = FALSE)

pdf(
  file = file.path(assoc_dir, "protein_property_mixed_association_heatmap_selected_vars.pdf"),
  width = 9,
  height = 8,
  bg = "white"
)
draw(ht)
dev.off()
```

## Figure S2: Correlogram

```{r correlogram, message=FALSE, warning=FALSE}
library(dplyr)
library(stringr)
library(corrplot)
library(viridisLite)

# Select continuous genotype predictors
geno_cont_vars <- var_cat %>%
  filter(
    Genotype_or_Phenotype == "Genotype",
    Type                 == "Continuous"
  ) %>%
  pull(Variable) %>%
  intersect(colnames(results_df), .)

# Subset + drop zero‐variance / too‐sparse
continuous_df <- results_df %>%
  select(severity, all_of(geno_cont_vars)) %>%
  select_if(function(col) {
    n_non_na <- sum(!is.na(col))
    sd_val   <- sd(col, na.rm = TRUE)
    n_non_na >= 10 && !is.na(sd_val) && sd_val > 0
  })

# Compute Pearson correlation
corr_matrix <- cor(
  as.matrix(continuous_df),
  use    = "pairwise.complete.obs",
  method = "pearson"
)

# Clean up names
clean_names <- colnames(corr_matrix) %>%
  str_replace_all("_", " ") %>%
  str_replace_all("\\.", " ") %>%
  str_replace_all("\\[aa\\]", "[aa]") %>%  
  str_squish()

rownames(corr_matrix) <- clean_names
colnames(corr_matrix) <- clean_names

# colors
my_colors <- viridis(200, option = "D")

# output directory
corr_out <- file.path(output_dir, "correlation analysis")
dir.create(corr_out, recursive = TRUE, showWarnings = FALSE)

# Plot & save
pdf(
  file   = file.path(corr_out, "correlogram_severity_vs_genotypes.pdf"),
  width  = 14,
  height = 14,
  family = "Helvetica"
)

par(font = 2, mar = c(1, 1, 2, 4))

corrplot(
  corr_matrix,
  method      = "color",
  type        = "upper",
  col         = my_colors,
  tl.col      = "black",
  tl.srt      = 45,
  tl.cex      = 1.0,
  tl.font     = 2,
  cl.cex      = 1.0, 
  addCoef.col = "black",
  number.cex  = 0.8,
  number.font = 2,   
  diag        = FALSE,
  cl.pos      = "r",
  cl.lim      = c(-1, 1)
)

# Legend title
mtext(
  text   = "Pearson r",
  side   = 4,
  line   = 2,
  at     = 0.5,
  cex    = 1.2,
  family = "Helvetica",
  font   = 2
)

# Main title
title(
  "Correlogram: Severity vs Continuous Genotypes",
  line      = 0.5,
  family    = "Helvetica",
  font.main = 2
)
dev.off()

```

## Figure S3: TITER predictions visualized

```{r lollipop-multiple-names, message=FALSE, warning=FALSE}
library(dplyr)
library(ggplot2)
library(readr)
library(scales)

# files and output directory
file_paths <- c(
  wt  = file.path("titer", "data", "wildtype_MAGEL2_candidate_predictions.csv"),
  s7  = file.path("titer", "data", "individual_patients", "SYS#007", "candidate_predictions.csv"),
  s55 = file.path("titer", "data", "individual_patients", "SYS#055", "candidate_predictions.csv")
)
out_dir <- file.path(plots_dir, "lollipop")
dir.create(out_dir, recursive = TRUE, showWarnings = FALSE)

# Loop through each file
for (id in names(file_paths)) {
  fp <- file_paths[[id]]
  df <- read_csv(fp, show_col_types = FALSE)

  # Compute mean & SD
  stats <- df %>% summarise(mu = mean(Probability_With_Prior, na.rm=TRUE),
                            sigma = sd(Probability_With_Prior, na.rm=TRUE))

  # Categorize & size
  df2 <- df %>%
    mutate(
      z        = (Probability_With_Prior - stats$mu) / stats$sigma,
      sd_group = case_when(
        z >  4  ~ "> 4 SD",
        z >  3  ~ "> 3 SD",
        z >  2  ~ "> 2 SD",
        z >  1  ~ "> 1 SD",
        TRUE    ~ "≤ 1 SD"
      ) %>% factor(levels=c("≤ 1 SD","> 1 SD","> 2 SD","> 3 SD","> 4 SD")),
      size_pt  = ifelse(sd_group != "≤ 1 SD",
                        scales::rescale(Probability_With_Prior, to=c(1,5)),
                        NA_real_)
    )

  # colors
  sd_colors <- c(
    "≤ 1 SD" = "#0072B2",
    "> 1 SD" = "#009E73",
    "> 2 SD" = "#F0E442",
    "> 3 SD" = "#D55E00",
    "> 4 SD" = "#CC79A7"
  )

  # plot
  p <- ggplot(df2, aes(x=CDS_Position, y=Probability_With_Prior)) +
    geom_hline(yintercept=stats$mu, linetype="dashed") +
    geom_segment(aes(xend=CDS_Position, yend=0, color=sd_group), size=0.6) +
    geom_point(data=filter(df2, sd_group!="≤ 1 SD"),
               aes(fill=sd_group, size=size_pt),
               shape=21, color="black", stroke=0.5) +
    geom_text(data=filter(df2, sd_group=="> 4 SD"),
              aes(label=CDS_Position),
              vjust=-1.2, size=3, family="Arial", fontface="bold") +
    scale_color_manual(values=sd_colors, name="Deviation from mean") +
    scale_fill_manual(values=sd_colors, guide=FALSE) +
    scale_size_identity() +
    labs(
      title    = "Candidate TIS Probabilities Along MAGEL2 CDS",
      subtitle = "Mean probability (dashed); colored by SD above mean",
      x        = "CDS Position (bp)",
      y        = "Probability (with prior)"
    ) +
    scale_x_continuous(
      expand = expansion(add=c(100,0), mult=c(0,0.02)),
      breaks = pretty_breaks(n=8)
    ) +
    scale_y_continuous(
      expand = expansion(mult=c(0,0.05)),
      breaks = pretty_breaks(n=6)
    ) +
    theme_minimal(base_family="Arial", base_size=14) +
    theme(
      text                = element_text(family="Arial", face="bold"),
      plot.title          = element_text(size=18, margin=margin(b=5)),
      plot.subtitle       = element_text(size=12, margin=margin(b=20)),
      plot.title.position = "plot",
      plot.margin         = margin(t=50, r=20, b=10, l=20),
      axis.title          = element_text(size=14),
      axis.text.x         = element_text(size=12, angle=45, hjust=1),
      axis.text.y         = element_text(size=12),
      axis.line           = element_line(size=0.8, color="black"),
      axis.ticks          = element_line(size=0.8, color="black"),
      axis.ticks.length   = unit(0.25, "cm"),
      panel.grid          = element_blank(),
      legend.position     = "right",
      legend.title        = element_text(size=12),
      legend.text         = element_text(size=10)
    )

  # filename
  fname <- switch(id,
    wt  = "wildtype_lollipop.png",
    s7  = "SYS007_1996dupC_lollipop.png",
    s55 = "SYS055_1996delC_lollipop.png"
  )

  ggsave(
    filename = fname,
    plot     = p,
    path     = out_dir,
    device   = "png",
    dpi      = 300,
    width    = 18,
    height   = 7
  )
}
```

## CSVs to .xlsx

Combine multiple .csv files into one .xlsx spreadsheet with multiple sheets

```{r multiple csv files to xlsx}
library(tools)

# helpers
`%||%` <- function(a, b) if (!is.null(a) && !is.na(a) && nzchar(a)) a else b

determine_folder <- function(default = NULL) {
  cand <- default %||% getOption("csv_folder") %||% Sys.getenv("CSV_FOLDER", "")
  if (nzchar(cand) && dir.exists(cand)) return(normalizePath(cand, winslash = "/"))

  if (interactive()) {
    if (requireNamespace("rstudioapi", quietly = TRUE) &&
        isTRUE(try(rstudioapi::isAvailable(), silent = TRUE))) {
      sel <- try(rstudioapi::selectDirectory(caption = "Select folder with CSV files"),
                 silent = TRUE)
      if (!inherits(sel, "try-error") && length(sel) && nzchar(sel)) return(sel)
    }
    if (requireNamespace("tcltk", quietly = TRUE)) {
      sel <- try(tcltk::tk_choose.dir(default = ".", caption = "Select folder with CSV files"),
                 silent = TRUE)
      if (!inherits(sel, "try-error") && !is.na(sel) && nzchar(sel)) return(sel)
    }
  }
  NULL
}

shorten_sheet_name <- function(name, maxlen = 31) {
  parts <- strsplit(name, "_", fixed = TRUE)[[1]]
  shortened <- parts
  repeat {
    cand <- paste(shortened, collapse = "_")
    if (nchar(cand) <= maxlen) return(cand)
    i <- which.max(nchar(shortened))
    if (nchar(shortened[i]) > 1) shortened[i] <- substr(shortened[i], 1, nchar(shortened[i]) - 1) else break
  }
  substr(paste(shortened, collapse = "_"), 1, maxlen)
}

# main
folder <- determine_folder()

if (is.null(folder) || !dir.exists(folder)) {
  message("No folder selected; skipping CSV → XLSX aggregation.")
} else {
  csv_files <- list.files(path = folder, pattern = "\\.csv$", full.names = TRUE)
  if (length(csv_files) == 0) {
    message("No CSV files found in: ", folder, ". Skipping.")
  } else {
    output_file <- file.path(folder, "combined.xlsx")

    if (requireNamespace("openxlsx", quietly = TRUE)) {
      wb <- openxlsx::createWorkbook()
      for (f in csv_files) {
        raw_name   <- file_path_sans_ext(basename(f))
        sheet_name <- shorten_sheet_name(make.names(raw_name))
        dat <- utils::read.csv(f, stringsAsFactors = FALSE, check.names = FALSE)
        openxlsx::addWorksheet(wb, sheetName = sheet_name)
        openxlsx::writeData(wb, sheet = sheet_name, x = dat)
      }
      openxlsx::saveWorkbook(wb, output_file, overwrite = TRUE)
      message("Combined Excel file saved to: ", output_file)
    } else if (requireNamespace("writexl", quietly = TRUE)) {
      sheets <- setNames(vector("list", length(csv_files)), nm = character(length(csv_files)))
      for (i in seq_along(csv_files)) {
        f <- csv_files[i]
        raw_name   <- file_path_sans_ext(basename(f))
        sheet_name <- shorten_sheet_name(make.names(raw_name))
        sheets[[i]] <- utils::read.csv(f, stringsAsFactors = FALSE, check.names = FALSE)
        names(sheets)[i] <- sheet_name
      }
      writexl::write_xlsx(sheets, path = output_file)
      message("Combined Excel file saved to: ", output_file)
    } else {
      message("Neither 'openxlsx' nor 'writexl' is installed; cannot write Excel. ",
              "Install one of them to enable export.")
    }
  }
}
```

## Workspace maintenance

Save current workspace image to allow later reloading

```{r save-current-workspace, message=TRUE, warning=FALSE}
folder <- file.path("saved_workspaces")
if(!dir.exists(folder)) dir.create(folder)
filename <- paste0("workspace_", Sys.Date(), ".RData")
filepath <- file.path(folder, filename)
save.image(filepath)
```

Load latest saved workspace

```{r load-saved-workspace, message=TRUE, warning=TRUE}

load_latest_workspace <- function() {
   folder <- file.path(getwd(), "saved_workspaces")
   if(!dir.exists(folder)) stop("No saved_workspaces directory")
   files <- list.files(path = folder, pattern = "^workspace_.*\\.RData$", full.names = TRUE)
   if(length(files) == 0) stop("No workspace images found")
   latest_file <- files[order(file.info(files)$mtime, decreasing = TRUE)][1]
   load(latest_file)
   message("Loaded workspace from file: ", latest_file)
}

load_latest_workspace()

```

# Analysis of FOXG1 and MKRN3 cohorts

```{r foxg1-analysis}

suppressPackageStartupMessages({
  library(dplyr)
  library(stringr)
  library(ComplexHeatmap)
  library(circlize)
  library(grid)
})

# ---- paths ----
csv_path <- "FOXG1 Cohort/FOXG1_MAP_results_2025-12-22.csv"
out_dir  <- file.path("FOXG1 Cohort", "Results")
dir.create(out_dir, recursive = TRUE, showWarnings = FALSE)

# 1) Load ----------------
df <- read.csv(csv_path, stringsAsFactors = FALSE, check.names = FALSE)
message("Loaded: ", nrow(df), " rows, ", ncol(df), " cols")

# 2) Helpers ----------------
to_numeric_safe <- function(x) {
  if (is.numeric(x)) return(x)
  if (is.logical(x)) return(as.numeric(x))
  x <- as.character(x)
  x[x == ""] <- NA
  suppressWarnings(as.numeric(x))
}

drop_all_na_or_zero_sd <- function(df_num) {
  all_na <- names(df_num)[vapply(df_num, function(x) all(is.na(x)), logical(1))]
  sds <- vapply(df_num, function(x) stats::sd(x, na.rm = TRUE), numeric(1))
  zero_sd <- names(sds)[is.na(sds) | sds == 0]
  keep <- setdiff(names(df_num), union(all_na, zero_sd))
  df_num[, keep, drop = FALSE]
}

p_to_star_nominal <- function(p) {
  if (is.na(p)) return("")
  if (p < 0.05) return("*")
  ""
}

plot_correlogram_square_fixed <- function(cor_plot, p_nominal_plot, file_name,
                                          row_labels, col_labels,
                                          row_order, col_order,
                                          low_col = "#005F73", mid_col = "white", high_col = "#AE2012") {
  
  col_fun <- circlize::colorRamp2(c(-1, 0, 1), c(low_col, mid_col, high_col))
  
  ht <- ComplexHeatmap::Heatmap(
    cor_plot,
    name = "r",
    col = col_fun,
    
    # --- fixed ordering ---
    cluster_rows = FALSE,
    cluster_columns = FALSE,
    row_order = row_order,
    column_order = col_order,
    
    # --- labels ---
    row_labels = row_labels,
    column_labels = col_labels,
    
    row_names_side = "left",
    column_names_rot = 45,
    
    rect_gp = grid::gpar(col = "white", lwd = 1),
    heatmap_legend_param = list(title = "Correlation"),
    
    width  = grid::unit(ncol(cor_plot), "cm"),
    height = grid::unit(nrow(cor_plot), "cm"),
    
    cell_fun = function(j, i, x, y, width, height, fill) {
      star <- p_to_star_nominal(p_nominal_plot[i, j])
      if (star != "") {
        grid::grid.text(star, x = x, y = y,
                        gp = gpar(fontsize = 12, fontface = "bold"))
      }
    }
  )
  
  pdf(file.path(out_dir, file_name),
      width = max(8, 0.35 * ncol(cor_plot) + 5),
      height = max(5, 0.45 * nrow(cor_plot) + 3))
  ComplexHeatmap::draw(ht)
  dev.off()
}

# --- vectorized recoders ---
recode_3lvl_motor <- function(x) {
  # unassisted=0, assisted=1, absent=2
  x <- tolower(trimws(as.character(x)))
  dplyr::case_when(
    x == "unassisted" ~ 0,
    x == "assisted"   ~ 1,
    x == "absent"     ~ 2,
    TRUE ~ NA_real_
  )
}

recode_present_absent_0_2 <- function(x) {
  x <- tolower(trimws(as.character(x)))
  dplyr::case_when(
    x == "absent"  ~ 0,
    x == "present" ~ 2,
    TRUE ~ NA_real_
  )
}

recode_hand_use <- function(x) {
  x <- tolower(trimws(as.character(x)))
  dplyr::case_when(
    x == "present" ~ 0,
    x == "absent"  ~ 2,
    TRUE ~ NA_real_
  )
}

recode_speech <- function(x) {
  # present=1, absent=2
  x <- tolower(trimws(as.character(x)))
  dplyr::case_when(
    x == "present" ~ 1,
    x == "absent"  ~ 2,
    TRUE ~ NA_real_
  )
}

recode_social_eye <- function(x) {
  x <- tolower(trimws(as.character(x)))
  dplyr::case_when(
    x == "good"    ~ 0,
    x == "poor"    ~ 1,
    x == "absent"  ~ 2,
    x == "present" ~ 0,  
    TRUE ~ NA_real_
  )
}

recode_sleep <- function(x) {
  x <- tolower(trimws(as.character(x)))
  dplyr::case_when(
    x == "absent"  ~ 0,
    x == "present" ~ 2,
    TRUE ~ NA_real_
  )
}

recode_feeding <- function(x) {
  x <- tolower(trimws(as.character(x)))
  dplyr::case_when(
    x == "absent" ~ 0,
    x %in% c("present", "g-tube") ~ 2,
    TRUE ~ NA_real_
  )
}


# 3) Variables ----------------
geno_vars <- c(
  "Locus",
  "Protein Length aa",
  "Unaltered Length aa",
  "Frameshift Length aa"
)

# Required for scoring items
sev_src <- c(
  "age last follow up",
  "HC.at.birth..SD.", "Length.at.follow.up..SDS.", "BMI..SD.", "HC.at.follow.up..SD.",
  "Sitting.at.follow.up", "Walking.at.follow.up", "Functional.hand.use.at.follow.up", "Speech.at.follow.up",
  "Social.interaction", "Eye.contact", "Abnormal.sleep.patterns",
  "Seizures", "Spasticity", "Stereotypic.movements", "Dyskinesia", "Kypho..scoliosis",
  "Feeding.difficulties",
  "Corpus.callosum.anomalies", "Cortical.anomalies", "delayed myelination",
  "FOXG1 Severity Score"
)

missing_needed <- setdiff(c(geno_vars, sev_src), names(df))
if (length(missing_needed) > 0) stop("Missing required columns: ", paste(missing_needed, collapse = ", "))


# 4) Create numeric severity-item score columns (0/1/2) + age gates ----------------
df2 <- df %>%
  mutate(
    age_num = to_numeric_safe(.data[["age last follow up"]]),
    
    # Somatic growth: SDS >= -2 => 0, < -2 => 2
    sev_somatic_HC_birth  = { v <- to_numeric_safe(.data[["HC.at.birth..SD."]]);          ifelse(is.na(v), NA_real_, ifelse(v >= -2, 0, 2)) },
    sev_somatic_Length_FU = { v <- to_numeric_safe(.data[["Length.at.follow.up..SDS."]]); ifelse(is.na(v), NA_real_, ifelse(v >= -2, 0, 2)) },
    sev_somatic_BMI       = { v <- to_numeric_safe(.data[["BMI..SD."]]);                  ifelse(is.na(v), NA_real_, ifelse(v >= -2, 0, 2)) },
    sev_somatic_HC_FU     = { v <- to_numeric_safe(.data[["HC.at.follow.up..SD."]]);      ifelse(is.na(v), NA_real_, ifelse(v >= -2, 0, 2)) },
    
    # Motor & speech (age-gated, months)
    sev_motor_sitting = ifelse(!is.na(age_num) & age_num > 12,
                               recode_3lvl_motor(.data[["Sitting.at.follow.up"]]), NA_real_),
    sev_motor_walking = ifelse(!is.na(age_num) & age_num > 24,
                               recode_3lvl_motor(.data[["Walking.at.follow.up"]]), NA_real_),
    sev_motor_handuse = ifelse(!is.na(age_num) & age_num > 12,
                               recode_hand_use(.data[["Functional.hand.use.at.follow.up"]]), NA_real_),
    sev_motor_speech  = ifelse(!is.na(age_num) & age_num > 24,
                               recode_speech(.data[["Speech.at.follow.up"]]), NA_real_),
    
    # Behavior
    sev_beh_social = recode_social_eye(.data[["Social.interaction"]]),
    sev_beh_eye    = recode_social_eye(.data[["Eye.contact"]]),
    sev_beh_sleep  = recode_sleep(.data[["Abnormal.sleep.patterns"]]),
    
    # Neurological features
    sev_neuro_seizures   = recode_present_absent_0_2(.data[["Seizures"]]),
    sev_neuro_spasticity = recode_present_absent_0_2(.data[["Spasticity"]]),
    sev_neuro_stereo     = recode_present_absent_0_2(.data[["Stereotypic.movements"]]),
    sev_neuro_dysk       = recode_present_absent_0_2(.data[["Dyskinesia"]]),
    sev_neuro_kypho      = recode_present_absent_0_2(.data[["Kypho..scoliosis"]]),
    sev_neuro_feeding    = recode_feeding(.data[["Feeding.difficulties"]]),
    
    # MRI
    sev_mri_cc   = recode_present_absent_0_2(.data[["Corpus.callosum.anomalies"]]),
    sev_mri_myel = recode_present_absent_0_2(.data[["delayed myelination"]]),
    sev_mri_cort = recode_present_absent_0_2(.data[["Cortical.anomalies"]])
  )

# Column order aligned with how score is organized in the original publication:
sev_item_cols <- c(
  # Somatic growth (4)
  "sev_somatic_HC_birth",
  "sev_somatic_Length_FU",
  "sev_somatic_BMI",
  "sev_somatic_HC_FU",
  
  # Motor and speech development (4; age-gated)
  "sev_motor_sitting",
  "sev_motor_walking",
  "sev_motor_handuse",
  "sev_motor_speech",
  
  # Behavior (3)
  "sev_beh_social",
  "sev_beh_eye",
  "sev_beh_sleep",
  
  # Neurological features (6)
  "sev_neuro_seizures",
  "sev_neuro_spasticity",
  "sev_neuro_stereo",
  "sev_neuro_dysk",
  "sev_neuro_kypho",
  "sev_neuro_feeding",
  
  # MRI anomalies (3)
  "sev_mri_cc",
  "sev_mri_myel",
  "sev_mri_cort",
  
  # Score
  "FOXG1 Severity Score"
)


# 5) Prepare numeric matrices ----------------
to_coerce <- unique(c(geno_vars, sev_item_cols))

df_num <- df2 %>%
  mutate(across(all_of(to_coerce), to_numeric_safe))

geno_df <- df_num[, geno_vars, drop = FALSE] %>% drop_all_na_or_zero_sd()
sev_df  <- df_num[, sev_item_cols, drop = FALSE] %>% drop_all_na_or_zero_sd()

geno_keep <- colnames(geno_df)
sev_keep  <- colnames(sev_df)

# enforce  order 
geno_keep <- geno_vars[geno_vars %in% geno_keep]
sev_keep  <- sev_item_cols[sev_item_cols %in% sev_keep]

if (length(geno_keep) < 1) stop("No usable genotype vars after cleaning.")
if (length(sev_keep)  < 1) stop("No usable severity vars after cleaning.")

message("Genotype vars used: ", paste(geno_keep, collapse = ", "))
message("Severity vars used: ", paste(sev_keep, collapse = ", "))


# 6) Correlation + p-values ----------------
cor_mat <- matrix(NA_real_, nrow = length(geno_keep), ncol = length(sev_keep),
                  dimnames = list(geno_keep, sev_keep))
p_mat <- cor_mat
n_mat <- cor_mat

for (i in seq_along(geno_keep)) {
  for (j in seq_along(sev_keep)) {
    x <- df_num[[geno_keep[i]]]
    y <- df_num[[sev_keep[j]]]
    ok <- stats::complete.cases(x, y)
    n_mat[i, j] <- sum(ok)
    if (sum(ok) >= 3L) {
      ct <- suppressWarnings(stats::cor.test(x[ok], y[ok], method = "pearson"))
      cor_mat[i, j] <- unname(ct$estimate)
      p_mat[i, j]   <- ct$p.value
    }
  }
}


# 7) Pretty labels ----------------
row_labels <- c(
  "Locus"               = "Locus (bp)",
  "Protein Length aa"   = "Protein Length (aa)",
  "Unaltered Length aa" = "Unaltered Length (aa)",
  "Frameshift Length aa"= "Frameshift length (aa)"
)

col_labels <- c(
  # Somatic growth
  "sev_somatic_HC_birth"  = "Head circumference at birth",
  "sev_somatic_Length_FU" = "Length at follow-up",
  "sev_somatic_BMI"       = "BMI at follow-up",
  "sev_somatic_HC_FU"     = "Head circumference at follow-up",
  
  # Motor & speech development
  "sev_motor_sitting" = "Sitting",
  "sev_motor_walking" = "Walking",
  "sev_motor_handuse" = "Functional hand use",
  "sev_motor_speech"  = "Speech",
  
  # Behavior
  "sev_beh_social" = "Social interaction",
  "sev_beh_eye"    = "Eye contact",
  "sev_beh_sleep"  = "Abnormal sleep patterns",
  
  # Neurological features
  "sev_neuro_seizures"   = "Seizures",
  "sev_neuro_spasticity" = "Spasticity",
  "sev_neuro_stereo"     = "Stereotypic movements",
  "sev_neuro_dysk"       = "Dyskinesia",
  "sev_neuro_kypho"      = "Kypho-/scoliosis",
  "sev_neuro_feeding"    = "Feeding difficulties",
  
  # MRI features
  "sev_mri_cc"   = "Corpus callosum anomalies",
  "sev_mri_myel" = "Delayed myelination",
  "sev_mri_cort" = "Cortical anomalies",
  
  # Score
  "FOXG1 Severity Score" = "FOXG1 severity score"
)


row_labels_use <- row_labels[geno_keep]
col_labels_use <- col_labels[sev_keep]


# 8) Write outputs + plot ----------------
write.csv(cor_mat, file.path(out_dir, "geno_sevitems_cor.csv"))
write.csv(p_mat,   file.path(out_dir, "geno_sevitems_p_nominal.csv"))
write.csv(n_mat,   file.path(out_dir, "geno_sevitems_n.csv"))

tidy_tbl <- expand.grid(geno = geno_keep, pheno = sev_keep, stringsAsFactors = FALSE) %>%
  mutate(
    r = as.vector(cor_mat),
    n = as.vector(n_mat),
    p_nominal = as.vector(p_mat)
  ) %>%
  arrange(p_nominal)

write.csv(tidy_tbl, file.path(out_dir, "geno_sevitems_correlations_long_with_p.csv"), row.names = FALSE)

plot_correlogram_square_fixed(
  cor_plot = cor_mat,
  p_nominal_plot = p_mat,
  file_name = "geno_vs_sevitems_correlogram_fixed_order_pretty.pdf",
  row_labels = row_labels_use,
  col_labels = col_labels_use,
  row_order = geno_keep,
  col_order = sev_keep
)

message("Done. Outputs in: ", out_dir)




# Boxplots of severity score vs
#   (1) Domain location of variant
#   (2) Lost functional domains

suppressPackageStartupMessages({
  library(dplyr)
  library(ggplot2)
  library(patchwork) 
})

# ---- paths ----
out_pdf <- file.path(out_dir, "FOXG1_severity_vs_domains.pdf")

# ---- plot dataframe ----

plot_df <- df %>%
  mutate(
    sev = as.numeric(`FOXG1 Severity Score`),
    domain_loc = trimws(`Domain Location Of Variant`),
    lost_domains = trimws(`Lost Functional Domains`)
  ) %>%
  mutate(
    domain_loc   = ifelse(is.na(domain_loc)   | domain_loc   == "", NA_character_, domain_loc),
    lost_domains = ifelse(is.na(lost_domains) | lost_domains == "", NA_character_, lost_domains)
  ) %>%
  filter(!is.na(sev)) %>%
  mutate(
    domain_loc   = factor(domain_loc,   levels = sort(unique(domain_loc[!is.na(domain_loc)]))),
    lost_domains = factor(lost_domains, levels = sort(unique(lost_domains[!is.na(lost_domains)])))
  )

# ---- subtle within-group shading by severity, fixed hue per domain group ----
shade_by_sev_subtle <- function(sev_vec, group_chr) {
  rng <- range(sev_vec, na.rm = TRUE)
  t <- if (is.finite(rng[1]) && is.finite(rng[2]) && rng[2] > rng[1]) {
    (sev_vec - rng[1]) / (rng[2] - rng[1])
  } else {
    rep(0.5, length(sev_vec))
  }

  t <- 0.5 + (t - 0.5) * 0.2
  
  pal <- switch(
    group_chr,
    "Conserved site"         = colorRamp(c("#F6E27F", "#C9A227")), 
    "Forkhead domain"        = colorRamp(c("#D98C6A", "#8C3B1F")), 
    "Groucho-binding domain" = colorRamp(c("#D9D9D9", "#7A7A7A")), 
    colorRamp(c("#D9D9D9", "#7A7A7A"))
  )
  rgb_mat <- pal(t)
  rgb(rgb_mat[,1], rgb_mat[,2], rgb_mat[,3], maxColorValue = 255)
}

# Add point color derived from domain_loc (reused across both plots)
df_domain <- plot_df %>%
  filter(!is.na(domain_loc)) %>%
  group_by(domain_loc) %>%
  mutate(point_col = shade_by_sev_subtle(sev, as.character(unique(domain_loc)))) %>%
  ungroup()

df_lost <- plot_df %>%
  filter(!is.na(lost_domains)) %>%
  group_by(domain_loc) %>%
  mutate(point_col = shade_by_sev_subtle(sev, as.character(unique(domain_loc)))) %>%
  ungroup() %>%
  mutate(
    # fallback for missing domain_loc
    point_col = ifelse(
      is.na(domain_loc),
      {
        rng <- range(sev, na.rm = TRUE)
        t <- if (rng[2] > rng[1]) (sev - rng[1]) / (rng[2] - rng[1]) else rep(0.5, length(sev))
        t <- 0.5 + (t - 0.5) * 0.2
        pal <- colorRamp(c("#D9D9D9", "#7A7A7A"))
        rgb_mat <- pal(t)
        rgb(rgb_mat[,1], rgb_mat[,2], rgb_mat[,3], maxColorValue = 255)
      },
      point_col
    )
  )



BOX_W <- 0.65
Y_LIM <- c(0, 2)

base_theme <- theme_classic(base_size = 12) +
  theme(axis.text.x = element_text(angle = 35, hjust = 1))

p1 <- ggplot(df_domain, aes(x = domain_loc, y = sev)) +
  geom_boxplot(width = BOX_W, outlier.shape = NA) +
  geom_point(
    aes(color = point_col),
    position = position_jitter(width = 0.15, height = 0),
    size = 2.6, alpha = 0.95, shape = 16
  ) +
  scale_color_identity() +
  coord_cartesian(ylim = Y_LIM) +
  labs(x = "Domain location of variant", y = "FOXG1 severity score") +
  base_theme

p2 <- ggplot(df_lost, aes(x = lost_domains, y = sev)) +
  geom_boxplot(width = BOX_W, outlier.shape = NA) +
  geom_point(
    aes(color = point_col),
    position = position_jitter(width = 0.15, height = 0),
    size = 2.6, alpha = 0.95, shape = 16
  ) +
  scale_color_identity() +
  coord_cartesian(ylim = Y_LIM) +
  labs(x = "Lost functional domains", y = "FOXG1 severity score") +
  base_theme

n_cat_domain <- df_domain %>% distinct(domain_loc) %>% nrow() %>% max(1)
n_cat_lost   <- df_lost   %>% distinct(lost_domains) %>% nrow() %>% max(1)

combined <- p1 + p2 + patchwork::plot_layout(ncol = 2, widths = c(n_cat_domain, n_cat_lost))
print(combined)

# ---- save ----
cm_per_cat <- 0.7
pdf_width_in  <- max(4.5, ((n_cat_domain + n_cat_lost) * cm_per_cat) / 2.54 + 1.5)
pdf_height_in <- 5

ggsave(out_pdf, combined, width = pdf_width_in, height = pdf_height_in, device = cairo_pdf)
message("Saved: ", out_pdf, " (panel widths ", n_cat_domain, ":", n_cat_lost, ")")

```

```{r mkrn3-analysis}


  library(dplyr)
  library(stringr)
  library(ComplexHeatmap)
  library(circlize)
  library(grid)

# ---- paths ----
csv_path <- "mkrn3_MAP_results_2025-12-17.csv"
out_dir  <- file.path("Results", "Schubert_2025_MAP")
dir.create(out_dir, recursive = TRUE, showWarnings = FALSE)

# 1) load
df <- read.csv(csv_path, stringsAsFactors = FALSE, check.names = FALSE)
message("Loaded: ", nrow(df), " rows, ", ncol(df), " cols")

# 2) Helpers

to_numeric_safe <- function(x) {
  if (is.numeric(x)) return(x)
  if (is.logical(x)) return(as.numeric(x))
  x <- as.character(x)
  x[x == ""] <- NA
  suppressWarnings(as.numeric(x))
}

drop_all_na_or_zero_sd <- function(df_num) {
  all_na <- names(df_num)[vapply(df_num, function(x) all(is.na(x)), logical(1))]
  sds <- vapply(df_num, function(x) stats::sd(x, na.rm = TRUE), numeric(1))
  zero_sd <- names(sds)[is.na(sds) | sds == 0]
  keep <- setdiff(names(df_num), union(all_na, zero_sd))
  df_num[, keep, drop = FALSE]
}

p_to_star_nominal <- function(p) {
  if (is.na(p)) return("")
  if (p < 0.05) return("*")
  ""
}

# Parse "LH basal and peak" 
parse_lh_basal_peak <- function(x) {
  x0 <- as.character(x)
  x0[x0 == ""] <- NA
  
  is_date_like <- !is.na(x0) & str_detect(x0, "^\\d{1,2}[./-]\\d{1,2}[./-]\\d{2,4}$")
  has_slash <- !is.na(x0) & str_detect(x0, "/")
  
  basal <- rep(NA_real_, length(x0))
  peak  <- rep(NA_real_, length(x0))
  
  parts <- str_split(x0[has_slash], "/", n = 2, simplify = TRUE)
  left  <- str_trim(parts[, 1]) |> str_replace_all("<", "")
  right <- str_trim(parts[, 2]) |> str_replace_all("<", "")
  
  basal[has_slash] <- suppressWarnings(as.numeric(left))
  peak[has_slash]  <- suppressWarnings(as.numeric(right))
  
  basal[is_date_like] <- NA_real_
  peak[is_date_like]  <- NA_real_
  
  malformed <- !is.na(x0) & !has_slash
  malformed[is_date_like] <- FALSE
  
  list(
    LH_basal = basal,
    LH_peak  = peak,
    flags = list(
      n_total = length(x0),
      n_has_slash = sum(has_slash, na.rm = TRUE),
      n_date_like = sum(is_date_like, na.rm = TRUE),
      n_malformed_non_slash = sum(malformed, na.rm = TRUE)
    )
  )
}

# correlogram
plot_correlogram_square <- function(cor_plot, p_nominal_plot, file_name,
                                    low_col = "#005F73", mid_col = "white", high_col = "#AE2012") {
  col_fun <- circlize::colorRamp2(c(-1, 0, 1), c(low_col, mid_col, high_col))
  
  ht <- ComplexHeatmap::Heatmap(
    cor_plot,
    name = "r",
    col = col_fun,
    cluster_rows = TRUE,
    cluster_columns = TRUE,
    row_names_side = "left",
    row_dend_side = "right",
    column_names_rot = 45,
    rect_gp = grid::gpar(col = "white", lwd = 1),
    heatmap_legend_param = list(title = "Correlation"),
    width  = grid::unit(ncol(cor_plot), "cm"), 
    height = grid::unit(nrow(cor_plot), "cm"),
    cell_fun = function(j, i, x, y, width, height, fill) {
      star <- p_to_star_nominal(p_nominal_plot[i, j])
      if (star != "") {
        grid::grid.text(star, x = x, y = y, gp = gpar(fontsize = 12, fontface = "bold"))
      }
    }
  )
  
  pdf(file.path(out_dir, file_name),
      width = max(7, 0.35 * ncol(cor_plot) + 4),
      height = max(6, 0.35 * nrow(cor_plot) + 4))
  ComplexHeatmap::draw(ht)
  dev.off()
}


# 3) Variables

geno_vars <- c("Locus", "AA Position", "Protein Length aa", "Frameshift Length aa", "Unaltered Length aa")

pheno_vars_base <- c("onset of puberty years", "age diagnosis y", "BA years", "TS",
                     "FSH basal", "E2", "T")


# 4) Preprocessing

lh <- parse_lh_basal_peak(df[["LH basal and peak"]])
df$LH_basal <- lh$LH_basal
df$LH_peak  <- lh$LH_peak

message("LH parsing: slash=", lh$flags$n_has_slash,
        ", date_like=", lh$flags$n_date_like,
        ", malformed_non_slash=", lh$flags$n_malformed_non_slash)

pheno_vars <- c(pheno_vars_base, "LH_basal", "LH_peak")

to_coerce <- unique(c(geno_vars, pheno_vars))
missing_needed <- setdiff(to_coerce, names(df))
if (length(missing_needed) > 0) stop("Missing required columns: ", paste(missing_needed, collapse = ", "))

df_num <- df %>%
  mutate(across(all_of(to_coerce), to_numeric_safe))

geno_df  <- df_num[, intersect(geno_vars, names(df_num)), drop = FALSE] %>% drop_all_na_or_zero_sd()
pheno_df <- df_num[, intersect(pheno_vars, names(df_num)), drop = FALSE] %>% drop_all_na_or_zero_sd()

geno_keep  <- colnames(geno_df)
pheno_keep <- colnames(pheno_df)

if (length(geno_keep) < 1) stop("No usable genotype vars after cleaning.")
if (length(pheno_keep) < 1) stop("No usable phenotype vars after cleaning.")

message("Genotype vars used: ", paste(geno_keep, collapse = ", "))
message("Phenotype vars used: ", paste(pheno_keep, collapse = ", "))

# 5)  correlogram + CSV 

cor_mat <- matrix(NA_real_, nrow = length(geno_keep), ncol = length(pheno_keep),
                  dimnames = list(geno_keep, pheno_keep))
p_mat   <- cor_mat
n_mat   <- cor_mat

for (i in seq_along(geno_keep)) {
  for (j in seq_along(pheno_keep)) {
    x <- df_num[[geno_keep[i]]]
    y <- df_num[[pheno_keep[j]]]
    ok <- stats::complete.cases(x, y)
    n_mat[i, j] <- sum(ok)
    if (sum(ok) >= 3L) {
      ct <- suppressWarnings(stats::cor.test(x[ok], y[ok], method = "pearson"))
      cor_mat[i, j] <- unname(ct$estimate)
      p_mat[i, j]   <- ct$p.value
    }
  }
}

# matrices
write.csv(cor_mat, file.path(out_dir, "geno_pheno_cor.csv"))
write.csv(p_mat,   file.path(out_dir, "geno_pheno_p_nominal.csv"))
write.csv(n_mat,   file.path(out_dir, "geno_pheno_n.csv"))

# long table
tidy_tbl <- expand.grid(geno = geno_keep, pheno = pheno_keep, stringsAsFactors = FALSE) %>%
  mutate(
    r = as.vector(cor_mat),
    n = as.vector(n_mat),
    p_nominal = as.vector(p_mat)
  ) %>%
  arrange(p_nominal)

write.csv(tidy_tbl, file.path(out_dir, "mkrn3_geno_pheno_correlations_long_with_p.csv"), row.names = FALSE)

# plot
plot_correlogram_square(cor_mat, p_mat, "mkrn3_geno_pheno_correlogram.pdf")
```
